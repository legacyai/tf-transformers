<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
<meta property="og:title" content="Tensorflow Transformers (tf-transformers)" />
  
<meta property="og:type" content="website" />
  
<meta property="og:url" content="index.html" />
  
<meta property="og:description" content="State-of-the-art Faster Natural Language Processing in TensorFlow 2.0. tf-transformers provides general-purpose architectures (BERT, GPT-2, RoBERTa, T5, Seq2..." />
  
<meta property="og:image" content="png location" />
  
<meta property="og:image:alt" content="Tensorflow Transformers (tf-transformers)" />
  
<meta name="twitter:image" content="png location">
<meta name="twitter:description" content="State-of-the-art Faster Transformer (NLP,CV,Audio) Based models in Tensorflow 2.0">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tensorflow Transformers (tf-transformers) &mdash; TF Transformers   documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/custom_from_huggingface.css" type="text/css" /><link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Quick tour" href="introduction_docs/quicktour.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="#"><img src="_static/transformers_mix.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                 
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="introduction_docs/quicktour.html">Quick tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="introduction_docs/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="introduction_docs/philosophy.html">Philosophy</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_doc/albert.html">ALBERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bert.html">BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt2.html">OpenAI GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/t5.html">T5</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mt5.html">MT5</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/roberta.html">RoBERTa</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/vit.html">Vision Transformer (ViT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/clip.html">CLIP</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/sentence_transformer.html">Sentence Transformer</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/1_read_write_tfrecords.html">Writing and Reading TFRecords</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html">Classify text (MRPC) with Albert</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/3_masked_lm_tpu.html">Train (Masked Language Model) with tf-transformers in TPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html">Classify Flowers (Image Classification) with ViT using multi-GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html">Create Sentence Embedding Roberta Model + Zeroshot from Scratch</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/6_prompt_engineering_clip.html">Prompt Engineering using CLIP</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/7_gpt2_question_answering_squad.html">GPT2 for QA using Squad V1 ( Causal LM )</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/8_code_code_java_to_csharp_t5.html">Code Java to C# using T5</a></li>
</ul>
<p class="caption"><span class="caption-text">TFLite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tflite_tutorials/albert_tflite.html">Albert TFlite</a></li>
<li class="toctree-l1"><a class="reference internal" href="tflite_tutorials/bert_tflite.html">Bert TFLite</a></li>
<li class="toctree-l1"><a class="reference internal" href="tflite_tutorials/roberta_tflite.html">Roberta TFLite</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_usage/text_generation_using_gpt2.html">Text Generation using GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_usage/text_generation_using_t5.html">Text Generation using T5</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_usage/sentence_transformers.html">Sentence Transformer in tf-transformers</a></li>
</ul>
<p class="caption"><span class="caption-text">Tokenizers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_doc/albert_tokenizer.html">ALBERT Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bigbird_tokenizer.html">BigBird Roberta Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/t5_tokenizer.html">T5 Tokenizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/clip_feature_extractor.html">CLIP Feature Extractor</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/vit_feature_extractor.html">ViT Feature Extractor</a></li>
</ul>
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="research/glue.html">Glue Model Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="research/long_block_sequencer.html">Long Block Sequencer</a></li>
</ul>
<p class="caption"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="benchmarks/gpt2.html">Benchmark GPT2</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks/t5.html">Benchmark T5</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks/albert.html">Benchmark Albert</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks/vit.html">Benchmark ViT</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks/imagenet_clip_benchmark.html">Benchmark CLIP</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">TF Transformers</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
      <li>Tensorflow Transformers (tf-transformers)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="tensorflow-transformers-tf-transformers">
<h1>Tensorflow Transformers (tf-transformers)<a class="headerlink" href="#tensorflow-transformers-tf-transformers" title="Permalink to this headline">¶</a></h1>
<p>State-of-the-art Faster Natural Language Processing in TensorFlow 2.0.</p>
<p>tf-transformers  provides general-purpose
architectures (BERT, GPT-2, RoBERTa, T5, Seq2Seq…) for Natural Language Understanding (NLU) and Natural
Language Generation (NLG) with over 32+ pretrained models in 100+ languages in TensorFlow 2.0.</p>
<p>tf-transformers is the fastest library for Transformer based architectures, comparing to existing similar
implementations in TensorFlow 2.0. It is 80x faster comparing to famous similar libraries like HuggingFace Tensorflow
2.0 implementations. For more details about benchmarking please look <cite>BENCHMARK</cite> here.</p>
<p>This is the documentation of our repository <cite>tf-transformers &lt;https://github.com/legacyai/tf-transformers&gt;</cite>. You can
also follow our documentation &lt;<a class="reference external" href="https://legacyai.github.com/tf-transformers">https://legacyai.github.com/tf-transformers</a>? that teaches how to use this library, as well as the
other features of this library.</p>
<div class="section" id="features">
<h2>Features<a class="headerlink" href="#features" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>High performance on NLU and NLG tasks</p></li>
<li><p>Low barrier to entry for educators and practitioners</p></li>
</ul>
<p>State-of-the-art NLP for everyone:</p>
<ul class="simple">
<li><p>Deep learning researchers</p></li>
<li><p>Hands-on practitioners</p></li>
<li><p>AI/ML/NLP teachers and educators</p></li>
</ul>
<p>Lower compute costs, smaller carbon footprint:</p>
<ul class="simple">
<li><p>Researchers can share trained models instead of always retraining</p></li>
<li><p>Practitioners can reduce compute time and production costs</p></li>
<li><p>8 architectures with over 30 pretrained models, some in more than 100 languages</p></li>
</ul>
<p>Choose the right framework for every part of a model’s lifetime:</p>
<ul class="simple">
<li><p>Train state-of-the-art models in 3 lines of code</p></li>
<li><p>Complete support for Tensorflow 2.0 models.</p></li>
<li><p>Seamlessly pick the right framework for training, evaluation, production</p></li>
</ul>
</div>
<div class="section" id="contents">
<h2>Contents<a class="headerlink" href="#contents" title="Permalink to this headline">¶</a></h2>
<p>The documentation is organized in five parts:</p>
<ul class="simple">
<li><p><strong>GET STARTED</strong> contains a quick tour, the installation instructions and some useful information about our philosophy
and a glossary.</p></li>
<li><p><strong>MODELS</strong> contains general documentation on how to use the library.</p></li>
<li><p><strong>MODEL USAGE</strong> contains quick examples on how to use the models.</p></li>
<li><p><strong>ADVANCED TUTORIALS</strong> contains more advanced guides that are more specific to training and inference in production.</p></li>
<li><p><strong>RESEARCH</strong> focuses on tutorials that have less to do with how to use the library but more about general research in
transformers model, most written in fast pre-process and TPU</p></li>
<li><p><strong>TFLITE</strong> contains quick examples on how to use tflite models.</p></li>
<li><p><strong>BENCHMARK</strong> contains quick examples on how to benchmark models and the results.</p></li>
</ul>
<p>The library currently contains Tensorflow implementations, pretrained model weights, usage scripts, tutorials and
conversion utilities for the following models.</p>
<div class="section" id="supported-models">
<h3>Supported models<a class="headerlink" href="#supported-models" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p><a class="reference internal" href="model_doc/albert.html"><span class="doc">ALBERT</span></a> (from Google Research and the Toyota Technological Institute at Chicago) released
with the paper <a class="reference external" href="https://arxiv.org/abs/1909.11942">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a>, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush
Sharma, Radu Soricut.</p></li>
<li><p><a class="reference internal" href="model_doc/bart.html"><span class="doc">BART</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/pdf/1910.13461.pdf">BART: Denoising Sequence-to-Sequence
Pre-training for Natural Language Generation, Translation, and Comprehension</a> by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman
Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.</p></li>
<li><p><a class="reference internal" href="model_doc/bert.html"><span class="doc">BERT</span></a> (from Google) released with the paper <a class="reference external" href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional
Transformers for Language Understanding</a> by Jacob Devlin, Ming-Wei Chang,
Kenton Lee and Kristina Toutanova.</p></li>
<li><p><span class="xref std std-doc">BERT For Sequence Generation</span> (from Google) released with the paper <a class="reference external" href="https://arxiv.org/abs/1907.12461">Leveraging
Pre-trained Checkpoints for Sequence Generation Tasks</a> by Sascha Rothe, Shashi
Narayan, Aliaksei Severyn.</p></li>
<li><p><a class="reference internal" href="model_doc/clip.html"><span class="doc">CLIP</span></a> (from OpenAI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2103.00020">Learning Transferable Visual Models From
Natural Language Supervision</a> by Alec Radford, Jong Wook Kim, Chris Hallacy,
Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen
Krueger, Ilya Sutskever.</p></li>
<li><p><a class="reference internal" href="model_doc/gpt2.html"><span class="doc">GPT-2</span></a> (from OpenAI) released with the paper <a class="reference external" href="https://blog.openai.com/better-language-models/">Language Models are Unsupervised Multitask
Learners</a> by Alec Radford*, Jeffrey Wu*, Rewon Child, David
Luan, Dario Amodei** and Ilya Sutskever**.</p></li>
<li><p><span class="xref std std-doc">M2M100</span> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2010.11125">Beyond English-Centric Multilingual
Machine Translation</a> by by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi
Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman
Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.</p></li>
<li><p><span class="xref std std-doc">MarianMT</span> Machine translation models trained using <a class="reference external" href="http://opus.nlpl.eu/">OPUS</a> data by
Jörg Tiedemann. The <a class="reference external" href="https://marian-nmt.github.io/">Marian Framework</a> is being developed by the Microsoft
Translator Team.</p></li>
<li><p><a class="reference internal" href="model_doc/mbart.html"><span class="doc">MBart</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2001.08210">Multilingual Denoising Pre-training for
Neural Machine Translation</a> by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li,
Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.</p></li>
<li><p><a class="reference internal" href="model_doc/mbart.html"><span class="doc">MBart-50</span></a> (from Facebook) released with the paper <a class="reference external" href="https://arxiv.org/abs/2008.00401">Multilingual Translation with Extensible
Multilingual Pretraining and Finetuning</a> by Yuqing Tang, Chau Tran, Xian Li,
Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.</p></li>
<li><p><a class="reference internal" href="model_doc/mt5.html"><span class="doc">MT5</span></a> (from Google AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2010.11934">mT5: A massively multilingual pre-trained
text-to-text transformer</a> by Linting Xue, Noah Constant, Adam Roberts, Mihir
Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.</p></li>
<li><p><a class="reference internal" href="model_doc/roberta.html"><span class="doc">RoBERTa</span></a> (from Facebook), released together with the paper a <a class="reference external" href="https://arxiv.org/abs/1907.11692">Robustly Optimized BERT
Pretraining Approach</a> by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar
Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.</p></li>
<li><p><a class="reference internal" href="model_doc/t5.html"><span class="doc">T5</span></a> (from Google AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/1910.10683">Exploring the Limits of Transfer Learning with a
Unified Text-to-Text Transformer</a> by Colin Raffel and Noam Shazeer and Adam
Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.</p></li>
<li><p><a class="reference internal" href="model_doc/vit.html"><span class="doc">Vision Transformer (ViT)</span></a> (from Google AI) released with the paper <a class="reference external" href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16
Words: Transformers for Image Recognition at Scale</a> by Alexey Dosovitskiy,
Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias
Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.</p></li>
</ol>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="introduction_docs/quicktour.html">Quick tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="introduction_docs/installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="introduction_docs/installation.html#installation-with-pip">Installation with pip</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction_docs/installation.html#editable-install">Editable install</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction_docs/installation.html#caching-models">Caching models</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction_docs/installation.html#do-you-want-to-run-a-tf-ransformer-model-on-a-mobile-device">Do you want to run a tf-ransformer model on a mobile device?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="introduction_docs/philosophy.html">Philosophy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="introduction_docs/philosophy.html#main-concepts">Main concepts</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_doc/albert.html">ALBERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertconfig">AlbertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertmodel">AlbertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert.html#albertencoder">AlbertEncoder</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bert.html">BERT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertconfig">BertConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertmodel">BertModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bert.html#bertencoder">BertEncoder</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/gpt2.html">OpenAI GPT2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2config">GPT2Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2model">GPT2Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/gpt2.html#gpt2encoder">GPT2Encoder</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/t5.html">T5</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5config">T5Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5model">T5Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5.html#t5encoder">T5Encoder</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/mt5.html">MT5</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5config">MT5Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5model">MT5Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/mt5.html#mt5encoder">MT5Encoder</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/roberta.html">RoBERTa</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaconfig">RobertaConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertamodel">RobertaModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/roberta.html#robertaencoder">RobertaEncoder</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/vit.html">Vision Transformer (ViT)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/vit.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/vit.html#vitconfig">ViTConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/vit.html#vitmodel">ViTModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/vit.html#vitencoder">ViTEncoder</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/clip.html">CLIP</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#cliptextconfig">CLIPTextConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#clipimageconfig">CLIPImageConfig</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#clipmodel">CLIPModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#clipencoder">CLIPEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#clipimageencoder">CLIPImageEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#cliptextencoder">CLIPTextEncoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip.html#clipfeatureextractortf">CLIPFeatureExtractorTF</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/sentence_transformer.html">Sentence Transformer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/sentence_transformer.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/sentence_transformer.html#sentencetransformer">SentenceTransformer</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/1_read_write_tfrecords.html">Writing and Reading TFRecords</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/1_read_write_tfrecords.html#load-data-and-tokenizer">Load Data and Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/1_read_write_tfrecords.html#write-tfrecord">Write TFRecord</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/1_read_write_tfrecords.html#read-tfrecords">Read TFRecords</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html">Classify text (MRPC) with Albert</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html#load-model-optimizer-trainer">Load Model, Optimizer , Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html#prepare-data-for-training">Prepare Data for Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html#prepare-dataset">Prepare Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html#wandb-configuration">Wandb configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html#accuracy-callback">Accuracy Callback</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html#train">Train :-)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html#visualize-tensorboard">Visualize Tensorboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html#save-and-serialize-model">Save and Serialize Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html#model-serialization-production">Model Serialization (Production)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html#advanced-serialization-include-pre-processing-with-models">Advanced Serialization (Include pre-processing with models)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/2_text_classification_imdb_albert.html#load-the-model-check-accuracy">Load the model + Check Accuracy</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/3_masked_lm_tpu.html">Train (Masked Language Model) with tf-transformers in TPU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/3_masked_lm_tpu.html#trainer-has-to-be-initialized-before-everything-only-in-tpu-sometimes">Trainer has to be initialized before everything only in TPU (sometimes).</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/3_masked_lm_tpu.html#load-model-optimizer-trainer">Load Model, Optimizer , Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/3_masked_lm_tpu.html#prepare-data-for-training">Prepare Data for Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/3_masked_lm_tpu.html#prepare-dataset">Prepare Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/3_masked_lm_tpu.html#wandb-configuration">Wandb configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/3_masked_lm_tpu.html#train">Train :-)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/3_masked_lm_tpu.html#load-the-model-from-checkpoint">Load the Model from checkpoint</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/3_masked_lm_tpu.html#test-model-performance">Test Model performance</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html">Classify Flowers (Image Classification) with ViT using multi-GPU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#prepare-data">Prepare Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#plot-few-examples">Plot few examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#load-model-optimizer-trainer">Load Model, Optimizer , Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#prepare-data-for-training">Prepare Data for Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#prepare-dataset">Prepare Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#wandb-configuration">Wandb Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#accuracy-callback">Accuracy Callback</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#train">Train :-)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#visualize-the-tensorboard">Visualize the Tensorboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#load-trained-model-for-testing-and-save-it-as-serialzed-model">Load Trained Model for Testing and Save it as serialzed model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#calculate-predictions">Calculate Predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#plot-confusion-matrix">Plot Confusion Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#model-serialization-production">Model Serialization (Production)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#advanced-serialization-include-pre-processing-with-models">Advanced Serialization (Include pre-processing with models)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#evaluate-accuracy-using-joint-serializaton-model">Evaluate Accuracy using joint Serializaton Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/4_image_classification_vit_multi_gpu.html#plot-mistakes-of-model">Plot Mistakes of Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html">Create Sentence Embedding Roberta Model + Zeroshot from Scratch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#prepare-training-tfrecords-using-quora">Prepare Training TFRecords using Quora</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#prepare-validation-tfrecords-using-sts-b">Prepare Validation TFRecords using STS-b</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#prepare-training-and-validation-dataset-from-tfrecords">Prepare  Training and Validation Dataset from TFRecords</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#build-sentence-transformer-model">Build Sentence Transformer Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#load-model-optimizer-trainer">Load Model, Optimizer , Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#wandb-configuration">Wandb Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#zero-shot-on-sts-before-training">Zero-Shot on STS before Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#set-hyperparameters-and-configs">Set Hyperparameters and Configs</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#train">Train :-)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#visualize-the-tensorboard">Visualize the Tensorboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#load-trained-model-for-testing-and-save-it-as-serialzed-model">Load Trained Model for Testing and Save it as serialzed model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#model-serialization-production">Model Serialization (Production)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#quora-sentence-embeddings">Quora Sentence Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/5_sentence_embedding_roberta_quora_zeroshot.html#most-similar-sentences">Most Similar Sentences</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/6_prompt_engineering_clip.html">Prompt Engineering using CLIP</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/6_prompt_engineering_clip.html#load-model-tokenizer-preprocessor">Load Model, Tokenizer, Preprocessor</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/6_prompt_engineering_clip.html#preparing-imagenet-labels-and-prompts">Preparing ImageNet labels and prompts</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/6_prompt_engineering_clip.html#prepare-text-embeddings">Prepare text embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/6_prompt_engineering_clip.html#loading-the-images">Loading the Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/6_prompt_engineering_clip.html#calculate-top-k-accuracy">Calculate top-k accuracy</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/7_gpt2_question_answering_squad.html">GPT2 for QA using Squad V1 ( Causal LM )</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/7_gpt2_question_answering_squad.html#load-data-tokenizer">Load Data, Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/7_gpt2_question_answering_squad.html#prepare-training-tfrecords-and-validation-tfrecords-using-squad-causal-and-prefix">Prepare Training TFRecords and Validation TFRecords using Squad ( causal and prefix )</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/7_gpt2_question_answering_squad.html#prepare-validation-tfrecords">Prepare Validation TFRecords</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/7_gpt2_question_answering_squad.html#wandb-configuration">Wandb Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/7_gpt2_question_answering_squad.html#load-model-optimizer-trainer">Load Model, Optimizer , Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/7_gpt2_question_answering_squad.html#set-hyperparameters-and-configs">Set Hyperparameters and Configs</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/7_gpt2_question_answering_squad.html#train-gpt2-causal">Train GPT2 Causal :-)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/7_gpt2_question_answering_squad.html#evaluation-script-squad-v1-exact-match-f1-score">Evaluation Script (Squad V1) - Exact match, F1 score</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/7_gpt2_question_answering_squad.html#evaluate-exact-match-and-f1-score-on-all-checkpoints-gpt2-causal">Evaluate ( exact match and F1 score ) on all checkpoints - GPT2 Causal</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/8_code_code_java_to_csharp_t5.html">Code Java to C# using T5</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/8_code_code_java_to_csharp_t5.html#load-model-optimizer-trainer">Load Model, Optimizer , Trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/8_code_code_java_to_csharp_t5.html#prepare-data-for-training">Prepare Data for Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/8_code_code_java_to_csharp_t5.html#prepare-dataset">Prepare Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/8_code_code_java_to_csharp_t5.html#wandb-configuration">Wandb Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/8_code_code_java_to_csharp_t5.html#train">Train :-)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/8_code_code_java_to_csharp_t5.html#load-and-serialize-model-for-text-generation">Load and Serialize Model for Text Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/8_code_code_java_to_csharp_t5.html#evaluate-on-test-bleu-score">Evaluate on Test ( BLEU ) score</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">TFLite</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tflite_tutorials/albert_tflite.html">Albert TFlite</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/albert_tflite.html#convert-a-model-to-tflite">Convert a Model to TFlite</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/albert_tflite.html#load-albert-model">Load Albert Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/albert_tflite.html#verify-models-inputs-and-outputs">Verify Models inputs and outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/albert_tflite.html#save-model-as-serialized-version">Save Model as Serialized Version</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/albert_tflite.html#convert-savedmodel-to-tflite">Convert SavedModel to TFlite</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/albert_tflite.html#load-tflite-model">Load TFlite Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/albert_tflite.html#assert-tflite-model-and-keras-model-outputs">Assert TFlite Model and Keras Model outputs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tflite_tutorials/bert_tflite.html">Bert TFLite</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/bert_tflite.html#convert-a-model-to-tflite">Convert a Model to TFlite</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/bert_tflite.html#verify-models-inputs-and-outputs">Verify Models inputs and outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/bert_tflite.html#save-model-as-serialized-version">Save Model as Serialized Version</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/bert_tflite.html#convert-savedmodel-to-tflite">Convert SavedModel to TFlite</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/bert_tflite.html#load-tflite-model">Load TFlite Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/bert_tflite.html#assert-tflite-model-and-keras-model-outputs">Assert TFlite Model and Keras Model outputs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tflite_tutorials/roberta_tflite.html">Roberta TFLite</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/roberta_tflite.html#convert-a-model-to-tflite">Convert a Model to TFlite</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/roberta_tflite.html#verify-models-inputs-and-outputs">Verify Models inputs and outputs</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/roberta_tflite.html#save-model-as-serialized-version">Save Model as Serialized Version</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/roberta_tflite.html#convert-savedmodel-to-tflite">Convert SavedModel to TFlite</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/roberta_tflite.html#load-tflite-model">Load TFlite Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="tflite_tutorials/roberta_tflite.html#assert-tflite-model-and-keras-model-outputs">Assert TFlite Model and Keras Model outputs</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Model Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_usage/text_generation_using_gpt2.html">Text Generation using GPT2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_gpt2.html#load-gpt2-model">Load GPT2 Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_gpt2.html#serialize-and-load">Serialize and load</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_gpt2.html#text-generation">Text-Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_gpt2.html#greedy-decoding">Greedy Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_gpt2.html#beam-decoding">Beam Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_gpt2.html#top-k-nucleus-sampling">Top K Nucleus Sampling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_usage/text_generation_using_t5.html">Text Generation using T5</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_t5.html#load-t5-model">Load T5 Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_t5.html#serialize-and-load">Serialize and load</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_t5.html#text-generation">Text-Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_t5.html#greedy-decoding">Greedy Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_t5.html#beam-decoding">Beam Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_t5.html#top-k-nucleus-sampling">Top K Nucleus Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_t5.html#advanced-serialization-include-preprocessing-decoding-together">Advanced Serialization (include preprocessing + Decoding Together)</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/text_generation_using_t5.html#load-advanced-model-and-generate-text">Load Advanced Model and Generate text</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_usage/sentence_transformers.html">Sentence Transformer in tf-transformers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_usage/sentence_transformers.html#load-sentence-t5-model">Load Sentence-t5 model</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/sentence_transformers.html#whats-my-model-input">Whats my model input?</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/sentence_transformers.html#whats-my-model-output">Whats my model output?</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/sentence_transformers.html#sentence-vectors">Sentence vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_usage/sentence_transformers.html#serialize-as-usual-and-load-it">Serialize as usual and load it</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Tokenizers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_doc/albert_tokenizer.html">ALBERT Tokenizer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert_tokenizer.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert_tokenizer.html#alberttokenizertftext">AlbertTokenizerTFText</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/albert_tokenizer.html#alberttokenizerlayer">AlbertTokenizerLayer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/bigbird_tokenizer.html">BigBird Roberta Tokenizer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird_tokenizer.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird_tokenizer.html#bigbirdrobertatokenizertftext">BigBirdRobertaTokenizerTFText</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/bigbird_tokenizer.html#bigbirdrobertatokenizerlayer">BigBirdRobertaTokenizerLayer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/t5_tokenizer.html">T5 Tokenizer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5_tokenizer.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5_tokenizer.html#t5tokenizertftext">T5TokenizerTFText</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/t5_tokenizer.html#t5tokenizerlayer">T5TokenizerLayer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/clip_feature_extractor.html">CLIP Feature Extractor</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip_feature_extractor.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/clip_feature_extractor.html#clipfeatureextractortf">CLIPFeatureExtractorTF</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_doc/vit_feature_extractor.html">ViT Feature Extractor</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_doc/vit_feature_extractor.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_doc/vit_feature_extractor.html#vitfeatureextractortf">ViTFeatureExtractorTF</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Research</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="research/glue.html">Glue Model Evaluation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#ax">ax</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#cola">cola</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#mnli">mnli</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#mnli-matched">mnli_matched</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#mnli-mismatched">mnli_mismatched</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#mrpc">mrpc</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#qnli">qnli</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#qqp">qqp</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#rte">rte</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#sst2">sst2</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#stsb">stsb</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#how-to-run-evaluation-using-tensorflow-transformers">How to run Evaluation using Tensorflow Transformers.</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#glue-score-calculated">GLUE SCORE calculated</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#id1">GLUE SCORE calculated</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/glue.html#how-to-change-the-base-model">How to change the base model?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="research/long_block_sequencer.html">Long Block Sequencer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="research/long_block_sequencer.html#advantages">Advantages</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/long_block_sequencer.html#code-and-results">Code and Results</a></li>
<li class="toctree-l2"><a class="reference internal" href="research/long_block_sequencer.html#rogue-score">Rogue SCORE</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="benchmarks/gpt2.html">Benchmark GPT2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/gpt2.html#tensorflow-transformers-tft">Tensorflow-Transformers. (tft)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/gpt2.html#huggingface-tensorflow-hf-tf">HuggingFace-Tensorflow. (hf-tf)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/gpt2.html#huggingface-pytorch-hf-pt">HuggingFace-PyTorch. (hf-pt)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/gpt2.html#huggingface-jax-hf-jax">HuggingFace-JAX. (hf-jax)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/gpt2.html#official-benchmarks-on-cnn-dailymail">Official Benchmarks on CNN DailyMail</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks/t5.html">Benchmark T5</a><ul>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/t5.html#tensorflow-transformers-tft">Tensorflow-Transformers. (tft)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/t5.html#huggingface-tensorflow-hf-tf">HuggingFace-Tensorflow. (hf-tf)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/t5.html#huggingface-pytorch-hf-pt">HuggingFace-PyTorch. (hf-pt)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/t5.html#huggingface-jax-hf-jax-not-available">HuggingFace-JAX. (hf-jax) (Not Available)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/t5.html#official-benchmarks-on-xsum">Official Benchmarks on XSUM</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks/albert.html">Benchmark Albert</a><ul>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/albert.html#tensorflow-transformers-tft">Tensorflow-Transformers. (tft)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/albert.html#huggingface-tensorflow-hf-tf">HuggingFace-Tensorflow. (hf-tf)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/albert.html#huggingface-pytorch-hf-pt">HuggingFace-PyTorch. (hf-pt)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/albert.html#huggingface-jax-hf-jax-not-available">HuggingFace-JAX. (hf-jax) (Not Available)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/albert.html#official-benchmarks-on-imdb">Official Benchmarks on IMDB</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks/vit.html">Benchmark ViT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/vit.html#tensorflow-transformers-tft">Tensorflow-Transformers. (tft)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/vit.html#huggingface-tensorflow-hf-tf">HuggingFace-Tensorflow. (hf-tf)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/vit.html#huggingface-pytorch-hf-pt">HuggingFace-PyTorch. (hf-pt)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/vit.html#official-benchmarks-on-keras-flowed-dataset-5000-samples">Official Benchmarks on Keras Flowed dataset (5000 samples)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks/imagenet_clip_benchmark.html">Benchmark CLIP</a><ul>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/imagenet_clip_benchmark.html#pytorch-clip-model">PyTorch CLIP Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/imagenet_clip_benchmark.html#load-clip-model-tf-transformers">Load CLIP Model tf-transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/imagenet_clip_benchmark.html#tf-with-clip-preprocess-pt-to-tf-data">TF with clip preprocess (pt to tf data)</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks/imagenet_clip_benchmark.html#tf-with-tf-io-preprocess-preprocess-on-the-fly">TF with tf.io preprocess (Preprocess on the fly)</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="introduction_docs/quicktour.html" class="btn btn-neutral float-right" title="Quick tour" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019, The TFT Team, Licenced under the Apache License, Version 2.0.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-83738774-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-83738774-2', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>