data:
    data_directory:
    train_batch_size: 32
task:
  max_seq_len: 4096
  decoder_seq_len: 256
  num_splits:
  use_gru_layer:
  projection_dimension:

trainer:
  dtype: bf16
  num_gpus: 0
  tpu_address:
  epochs: 20
  strategy: mirrored
  steps_per_epoch: 50000
  model_checkpoint_dir:
  callback_steps: 10000
optimizer:
  learning_rate: 1e-4
  loss_type:
  use_constant_lr: false
model:
  is_training: true
  use_dropout: true
  num_layers: 12
  model_name:
