task:
  data_directory:
  max_seq_len: 512
  train_batch_size: 128
trainer:
  dtype: bf16
  num_gpus: 0
  tpu_address:
  epochs: 100
  strategy: mirrored
  steps_per_epoch: 10000
  model_checkpoint_dir:
  global_norm: 1.0
optimizer:
  learning_rate:  0.001
  num_warmup_steps: 0.1
  decay_function: cosine
  adam_beta_1: 0.9
  adam_beta_2: 0.95
  adam_epsilon: 10e-8
  weight_decay_rate: 0.1
  optimizer_type: adamw
  loss_type:
  use_constant_lr: false
model:
  is_training: true
  use_dropout: true
  model_name:
  num_layers: 12
