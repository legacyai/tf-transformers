{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178f5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/sarathrnair/Projects/tf-transformers/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d257a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3676a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarathrnair/miniforge3/envs/venv_tf_mac/lib/python3.9/site-packages/jax/_src/lib/__init__.py:34: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from unet import UnetModel\n",
    "from tf_transformers.models import SentenceTransformer\n",
    "from base_diffusion import BaseDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a1e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "708e27ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successful ✅✅: Model checkpoints matched and loaded from /Users/sarathrnair/.cache/huggingface/hub/tftransformers__sentence-t5-base-sentence-transformers.main.d64dbdc4c8c15637da4215b81f38af99d48a586c/ckpt-1\n",
      "INFO:absl:Successful ✅: Loaded model from tftransformers/sentence-t5-base-sentence-transformers\n"
     ]
    }
   ],
   "source": [
    "model_name = 'sentence-transformers/sentence-t5-base'\n",
    "text_encoder = SentenceTransformer.from_pretrained(model_name, return_layer=True)\n",
    "text_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73aa891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebdb2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ds res 32\n",
      "Ds res 16\n",
      "Ds res 8\n",
      "Ds res 8\n",
      "Current out channel 2048\n",
      "Up res start 8\n",
      "Up res 16\n",
      "Up res 32\n",
      "Up res 64\n",
      "Up res 64\n",
      "H start (None, 64, 64, 512)\n",
      "H (None, 32, 32, 512)\n",
      "H (None, 16, 16, 1024)\n",
      "H (None, 8, 8, 1536)\n",
      "H (None, 8, 8, 2048)\n",
      "Hs [<tf.Tensor 'unet/down_block/downsample/BiasAdd:0' shape=(None, 32, 32, 512) dtype=float32>, <tf.Tensor 'unet/down_block/attention/self_attention_layer_norm/batchnorm_1/add_1:0' shape=(None, 16, 16, 1024) dtype=float32>, <tf.Tensor 'unet/down_block/attention/self_attention_layer_norm/batchnorm_3/add_1:0' shape=(None, 8, 8, 1536) dtype=float32>, <tf.Tensor 'unet/down_block/attention/self_attention_layer_norm/batchnorm_5/add_1:0' shape=(None, 8, 8, 2048) dtype=float32>]\n",
      "Hs len 4\n",
      "Hs len 3\n",
      "Ublocks 4\n",
      "H middle (None, 8, 8, 2048)\n",
      "H up (None, 16, 16, 512)\n",
      "H up (None, 32, 32, 1024)\n",
      "H up (None, 64, 64, 1536)\n",
      "H up (None, 64, 64, 2048)\n"
     ]
    }
   ],
   "source": [
    "out_channels = 512\n",
    "channel_mult = [1, 2, 3, 4]\n",
    "num_res_blocks = 3\n",
    "time_emb = 128\n",
    "text_emb = 768\n",
    "input_channels = 3\n",
    "\n",
    "unet = UnetModel(\n",
    "                text_embedding_dimension=text_emb, # Make sure output of text encoder matches this\n",
    "                time_embedding_dimension=time_emb, # This should be same in BaseDiffusion model\n",
    "                out_channels=out_channels, \n",
    "                channel_mult = channel_mult,\n",
    "                input_channels=input_channels,\n",
    "                num_res_blocks = num_res_blocks,\n",
    "                attention_resolutions=[32, 16, 8],\n",
    "                cross_attention_resolutions=[32, 16, 8],\n",
    "                use_scale_shift_norm=True,\n",
    "\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ae9038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1278110723"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb7eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1305709571"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d158eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37feea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7826bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['beta_schedule'] = 'cosine'\n",
    "config['diffusion_steps'] = 128\n",
    "config['time_emb_dimension'] = time_emb\n",
    "config['image_height'] = 32\n",
    "config['image_width'] = 32\n",
    "config['input_channels'] = input_channels\n",
    "\n",
    "model = BaseDiffusion(config,\n",
    "                     text_encoder_model=text_encoder, \n",
    "                     unet_model=unet)\n",
    "\n",
    "model = model.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00579ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_pixels': <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'input_pixels')>,\n",
       " 'input_ids': <KerasTensor: shape=(None, None) dtype=int32 (created by layer 'input_ids')>,\n",
       " 'input_mask': <KerasTensor: shape=(None, None) dtype=int32 (created by layer 'input_mask')>,\n",
       " 'time_steps': <KerasTensor: shape=(1, None) dtype=int32 (created by layer 'time_steps')>,\n",
       " 'noise': <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'input_noise')>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8318f218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h': <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'diffusion')>,\n",
       " 'noise': <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'diffusion')>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfef8515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_serialized(\"/tmp/diffusion_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5db2edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded = tf.saved_model.load(\"/tmp/diffusion_temp\")\n",
    "# model = loaded.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216d88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733828fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "text_sequence_length = 96\n",
    "height = config['image_height']\n",
    "width  = config['image_width']\n",
    "in_channels = config['input_channels']\n",
    "diffusion_steps = config['diffusion_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a5e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cba3644",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.random.uniform((batch_size, height, width, in_channels)) # original image\n",
    "\n",
    "input_ids = tf.random.uniform(minval=0, maxval=100, shape=(batch_size, text_sequence_length), dtype=tf.int32)\n",
    "input_mask = tf.random.uniform(minval=0, maxval=2, shape=(batch_size, text_sequence_length), dtype=tf.int32)\n",
    "time_steps = tf.random.uniform(minval=0, maxval=diffusion_steps, shape=(1, batch_size), dtype=tf.int32) # time steps\n",
    "\n",
    "noise = tf.random.uniform((batch_size, height, width, in_channels)) # noise image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06667edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "inputs['input_pixels'] = image\n",
    "inputs['noise'] = noise\n",
    "inputs['input_ids'] = input_ids\n",
    "inputs['input_mask'] = input_mask\n",
    "inputs['time_steps'] = time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5316d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c15ee509",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d03702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d8d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_res = image_height # Set downsample_resolution to be same as image_height\n",
    "\n",
    "for index, ch_mult in enumerate(channel_mult):\n",
    "    if index == len(channel_mult) - 1:\n",
    "        use_downsample = False\n",
    "    else:\n",
    "        use_downsample = True\n",
    "        \n",
    "    current_out_channel = ch_mult * out_channels\n",
    "    \n",
    "    layers = []\n",
    "    for resnet_counter in range(num_res_blocks):\n",
    "        \n",
    "        res = ResNetBlock(\n",
    "                    current_out_channel, use_scale_shift_norm=use_scale_shift_norm, name='resnet_{}'.format(resnet_counter)\n",
    "                        )\n",
    "        \n",
    "        self_attn = tf.identity\n",
    "        if ds_res in attention_resolutions:\n",
    "            self_attn = ImageSelfAttention()\n",
    "        \n",
    "        cross_attn = tf.identity\n",
    "        if ds_res in cross_attention_resolutions:\n",
    "            cross_attn = ImageTextCrossAttention()\n",
    "        \n",
    "        down_sample = tf.identity\n",
    "        if use_downsample:\n",
    "            down_sample = tf.keras.layers.Conv2D(\n",
    "                out_channels, kernel_size=(3, 3), strides=(2, 2), use_bias=True, padding='SAME', name='downsample_{}'.format(index)\n",
    "            )\n",
    "            ds_res = ds_res // 2\n",
    "        \n",
    "        layers.append(res, attn, cross_attn, down_sample)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    self.d_blocks.append(\n",
    "        DownBlock(\n",
    "            current_out_channel,\n",
    "            use_self_attention=use_self_attention[index],\n",
    "            use_cross_attention=use_cross_attention[index],\n",
    "            use_downsample=use_downsample,\n",
    "            use_scale_shift_norm=use_scale_shift_norm,\n",
    "        )\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
