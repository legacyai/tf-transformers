{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178f5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/sarathrnair/Projects/tf-transformers/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d257a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3676a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarathrnair/miniforge3/envs/venv_tf_mac/lib/python3.9/site-packages/jax/_src/lib/__init__.py:34: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from unet import UnetModel\n",
    "from tf_transformers.models import SentenceTransformer\n",
    "from gaussian_diffusion import GaussianDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a1e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "708e27ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successful ✅✅: Model checkpoints matched and loaded from /Users/sarathrnair/.cache/huggingface/hub/tftransformers__sentence-t5-base-sentence-transformers.main.d64dbdc4c8c15637da4215b81f38af99d48a586c/ckpt-1\n",
      "INFO:absl:Successful ✅: Loaded model from tftransformers/sentence-t5-base-sentence-transformers\n"
     ]
    }
   ],
   "source": [
    "model_name = 'sentence-transformers/sentence-t5-base'\n",
    "text_encoder = SentenceTransformer.from_pretrained(model_name, return_layer=True)\n",
    "text_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73aa891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aebdb2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 128\n",
    "\n",
    "channel_mult = [1, 2, 3, 4]\n",
    "num_res_blocks = 3\n",
    "time_emb = 128\n",
    "text_emb = 768\n",
    "input_channels = 3\n",
    "\n",
    "unet = UnetModel(\n",
    "                text_embedding_dimension=text_emb, # Make sure output of text encoder matches this\n",
    "                time_embedding_dimension=time_emb, # This should be same in BaseDiffusion model\n",
    "                out_channels=out_channels, \n",
    "                channel_mult = channel_mult,\n",
    "                input_channels=input_channels,\n",
    "                num_res_blocks = num_res_blocks,\n",
    "                attention_resolutions=[32, 16, 8],\n",
    "                cross_attention_resolutions=[32, 16, 8],\n",
    "                use_scale_shift_norm=True,\n",
    "\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0741e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97237763"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ee65184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97237763"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c4007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae7826bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['beta_schedule'] = 'linear'\n",
    "config['diffusion_steps'] = 1000\n",
    "config['image_height'] = 32\n",
    "config['image_width'] = 32\n",
    "config['input_channels'] = input_channels\n",
    "\n",
    "model = GaussianDiffusion(config,\n",
    "                     text_encoder_model=text_encoder, \n",
    "                     unet_model=unet)\n",
    "\n",
    "model = model.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c400a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a04b1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "text_sequence_length = 96\n",
    "height = config['image_height']\n",
    "width  = config['image_width']\n",
    "in_channels = config['input_channels']\n",
    "diffusion_steps = config['diffusion_steps']\n",
    "\n",
    "image = tf.random.uniform((batch_size, height, width, in_channels)) # original image\n",
    "\n",
    "input_ids = tf.random.uniform(minval=0, maxval=100, shape=(batch_size, text_sequence_length), dtype=tf.int32)\n",
    "input_mask = tf.random.uniform(minval=0, maxval=2, shape=(batch_size, text_sequence_length), dtype=tf.int32)\n",
    "time_steps = tf.random.uniform(minval=0, maxval=diffusion_steps, shape=(1, batch_size), dtype=tf.int32) # time steps\n",
    "\n",
    "noise = tf.random.uniform((batch_size, height, width, in_channels)) # noise image\n",
    "\n",
    "inputs = {}\n",
    "inputs['input_pixels'] = image\n",
    "inputs['noise'] = noise\n",
    "inputs['input_ids'] = input_ids\n",
    "inputs['input_mask'] = input_mask\n",
    "inputs['time_steps'] = time_steps\n",
    "\n",
    "model_outputs = model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c77804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00579ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_pixels': <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'input_pixels')>,\n",
       " 'time_steps': <KerasTensor: shape=(1, None) dtype=int32 (created by layer 'time_steps')>,\n",
       " 'noise': <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'input_noise')>,\n",
       " 'input_ids': <KerasTensor: shape=(None, None) dtype=int32 (created by layer 'input_ids')>,\n",
       " 'input_mask': <KerasTensor: shape=(None, None) dtype=int32 (created by layer 'input_mask')>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8318f218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xpred': <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'diffusion')>,\n",
       " 'noise': <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'diffusion')>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfef8515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 16:12:58.108475: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as tf_transformers/t5_encoder_layer_call_fn, tf_transformers/t5_encoder_layer_call_and_return_conditional_losses, unet_layer_call_fn, unet_layer_call_and_return_conditional_losses, tf_transformers/t5_encoder_layer_call_fn while saving (showing 5 of 2680). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/diffusion_temp2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/diffusion_temp2/assets\n"
     ]
    }
   ],
   "source": [
    "model.save_serialized(\"/tmp/diffusion_temp2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5db2edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(\"/tmp/diffusion_temp2\")\n",
    "model = loaded.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216d88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "733828fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f4242cc",
   "metadata": {},
   "source": [
    "### Without Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cba3644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "input_channels = 3\n",
    "\n",
    "config = {}\n",
    "config['beta_schedule'] = 'linear'\n",
    "config['diffusion_steps'] = 1000\n",
    "config['image_height'] = 32\n",
    "config['image_width'] = 32\n",
    "config['input_channels'] = input_channels\n",
    "\n",
    "out_channels = 128\n",
    "\n",
    "channel_mult = [1, 2, 3, 4]\n",
    "num_res_blocks = 3\n",
    "time_emb = 128\n",
    "text_emb = 768\n",
    "input_channels = 3\n",
    "\n",
    "unet = UnetModel(\n",
    "                text_embedding_dimension=None, # None\n",
    "                time_embedding_dimension=time_emb, # This should be same in BaseDiffusion model\n",
    "                out_channels=out_channels, \n",
    "                channel_mult = channel_mult,\n",
    "                input_channels=input_channels,\n",
    "                num_res_blocks = num_res_blocks,\n",
    "                attention_resolutions=[32, 16, 8],\n",
    "                use_scale_shift_norm=True,\n",
    "\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "model = GaussianDiffusion(config,\n",
    "                     text_encoder_model=None, \n",
    "                     unet_model=unet)\n",
    "\n",
    "model = model.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be27da34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87483267"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.get_model().count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f113b533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87483267"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06667edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_pixels': <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'input_pixels')>,\n",
       " 'time_steps': <KerasTensor: shape=(1, None) dtype=int32 (created by layer 'time_steps')>,\n",
       " 'noise': <KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'input_noise')>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f5316d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_pixels': <KerasTensor: shape=(None, 64, 64, 3) dtype=float32 (created by layer 'input_pixels')>,\n",
       " 'time_steps': <KerasTensor: shape=(1, None) dtype=int32 (created by layer 'time_steps')>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ee509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d03702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d8d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
