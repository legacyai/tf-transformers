{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "857a80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sidhu/Documents/tf-transformers/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c329885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_text as text\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a133928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5125f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "\n",
    "vocab_file = 'bert_tokenizer_dir/vocab.txt'\n",
    "def _create_vocab_table_and_initializer(vocab_file):\n",
    "    vocab_initializer = tf.lookup.TextFileInitializer(\n",
    "        vocab_file,\n",
    "        key_dtype=tf.string, key_index=tf.lookup.TextFileIndex.WHOLE_LINE,\n",
    "        value_dtype=tf.int64, value_index=tf.lookup.TextFileIndex.LINE_NUMBER)\n",
    "    vocab_table = tf.lookup.StaticHashTable(vocab_initializer, default_value=-1)\n",
    "    return vocab_table, vocab_initializer\n",
    "\n",
    "vocab_table , vocab_initializer = _create_vocab_table_and_initializer(vocab_file)\n",
    "bert_tokenizer = text.BertTokenizer(\n",
    "        vocab_table, lower_case=False)\n",
    "\n",
    "CLS_ID, SEP_ID, PAD_ID, UNK_ID, MASK_ID = (101, 102, 0, 100, 103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906c5fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /home/sidhu/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c82f0c9f2b24a089abc99b867ccdbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6eea6263d8a40f4bc32b015cb46a67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-train.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-test.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-unsupervised.tfrecord...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /home/sidhu/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "imdb = tfds.load('imdb_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d2bee158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_input_and_labels(encoded_texts):\n",
    "    # 15% BERT masking\n",
    "    inp_mask = np.random.rand(*encoded_texts.shape) < 0.15\n",
    "    # Do not mask special tokens\n",
    "    inp_mask[encoded_texts == CLS_ID] = False\n",
    "    inp_mask[encoded_texts == SEP_ID] = False    \n",
    "    # Set targets to -1 by default, it means ignore\n",
    "    labels = -1 * np.ones(encoded_texts.shape, dtype=int)\n",
    "    # Set labels for masked tokens\n",
    "    labels[inp_mask] = encoded_texts[inp_mask]\n",
    "\n",
    "    # Prepare input\n",
    "    encoded_texts_masked = np.copy(encoded_texts)\n",
    "    # Set input to [MASK] which is the last token for the 90% of tokens\n",
    "    # This means leaving 10% unchanged\n",
    "    inp_mask_2mask = inp_mask & (np.random.rand(*encoded_texts.shape) < 0.90)\n",
    "    encoded_texts_masked[\n",
    "        inp_mask_2mask\n",
    "    ] = MASK_ID  # mask token is the last in the dict\n",
    "\n",
    "    # Set 10% to a random token\n",
    "    inp_mask_2random = inp_mask_2mask & (np.random.rand(*encoded_texts.shape) < 1 / 9)\n",
    "    encoded_texts_masked[inp_mask_2random] = np.random.randint(\n",
    "        3, MASK_ID, inp_mask_2random.sum()\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Prepare sample_weights to pass to .fit() method\n",
    "    sample_weights = np.ones(labels.shape)\n",
    "    sample_weights[labels == -1] = 0\n",
    "\n",
    "    # y_labels would be same as encoded_texts i.e input tokens\n",
    "    y_labels = np.copy(encoded_texts)\n",
    "    \n",
    "    # Extract masked lm positions (where we have masked)\n",
    "    # and use tf.ragged to convert it into tensor\n",
    "    indexes, positions = np.where(encoded_texts_masked == MASK_ID)\n",
    "    unique, counts = np.unique(indexes, return_counts=True)\n",
    "    counts = counts[:-1] # an extra at last (dont know)\n",
    "    counts = np.cumsum(counts)\n",
    "    masked_lm_positions = tf.ragged.constant(np.split(positions, counts))\n",
    "    masked_lm_positions = masked_lm_positions.to_tensor(PAD_ID)\n",
    "    \n",
    "    # Gather the positions we want\n",
    "    y_labels = np.take_along_axis(y_labels, masked_lm_positions.numpy(), axis=1)\n",
    "    sample_weights = np.take_along_axis(sample_weights, masked_lm_positions.numpy(), axis=1)\n",
    "    \n",
    "    return encoded_texts_masked, y_labels, sample_weights, masked_lm_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "fd5fb257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlm(encoded_text):\n",
    "    # Input to `augment()` is a TensorFlow tensor which\n",
    "    # is not supported by `imgaug`. This is why we first\n",
    "    # convert it to its `numpy` variant.\n",
    "    return get_masked_input_and_labels(encoded_text.numpy())\n",
    "\n",
    "def add_start_end(ragged):\n",
    "    count = ragged.bounding_shape()[0]\n",
    "    starts = tf.fill([count,1], CLS_ID)\n",
    "    ends = tf.fill([count,1], SEP_ID)\n",
    "    return tf.concat([starts, ragged, ends], axis=1)\n",
    "\n",
    "\n",
    "MAX_SEQ_LEN = 128\n",
    "def text_to_instance(batch):\n",
    "    text = batch['text']\n",
    "    encoded_text = bert_tokenizer.tokenize(text)\n",
    "    encoded_text = tf.cast(encoded_text.merge_dims(-2, -1), tf.int32)\n",
    "    encoded_text = encoded_text[:, :MAX_SEQ_LEN-2]\n",
    "    encoded_text = add_start_end(encoded_text)\n",
    "    encoded_text = encoded_text.to_tensor()\n",
    "    \n",
    "    input_ids, masked_lm_labels, masked_lm_weights, masked_lm_positions = tf.py_function(create_mlm, [encoded_text],\n",
    "                                                                    [tf.int32, tf.int32, tf.float32, tf.int32])\n",
    "        \n",
    "    # masked_lm_labels = get_2d_from_2d(masked_lm_labels, masked_lm_positions)\n",
    "    # masked_lm_weights = get_2d_from_2d(masked_lm_weights, masked_lm_positions)\n",
    "    \n",
    "    input_type_ids = tf.zeros_like(input_ids)\n",
    "    input_mask     = tf.ones_like(input_ids)\n",
    "    \n",
    "    inputs = {}\n",
    "    inputs['input_ids'] = input_ids\n",
    "    inputs['input_type_ids'] = input_type_ids\n",
    "    inputs['input_mask'] = input_mask\n",
    "    inputs['masked_lm_positions'] = masked_lm_positions\n",
    "    \n",
    "    labels = {}\n",
    "    labels['masked_lm_labels'] = masked_lm_labels\n",
    "    labels['masked_lm_mask']   = masked_lm_weights\n",
    "    \n",
    "    return (inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "09d18f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "dataset_unsupervised = imdb['unsupervised']\n",
    "dataset_unsupervised = dataset_unsupervised.batch(batch_size)\n",
    "dataset_unsupervised = dataset_unsupervised.map(text_to_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "fb70c128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(5, 128), dtype=int32, numpy=\n",
      "array([[  101, 16625,  2346, 17656,  9637,   118,  1986,  3650,  1103,\n",
      "         3830,   146,  1525,  1122,  1177,   103,  1115,  1103,  2006,\n",
      "         2523,  2274,  1282,  1107,   103, 18976,  1105,  1296,  1959,\n",
      "         1144,   170,  1472,   103,   103,  2431, 21718,  1673,  1234,\n",
      "         1138,  1242,  1472,  5402,   103,  1147,  5935,   117,  1133,\n",
      "          103,  1274,   103,   189,  1519,  1172,   103,  7065,   118,\n",
      "          118,  1152,  1132,  4013,   119,  8491,   112,   188,  1672,\n",
      "          103,  1105,  2993,  1127,  1825,   103,  1107,  1296,  1959,\n",
      "          119,  1109, 21803,  1534,   113,  7872,   153,    69,   103,\n",
      "          114,   117,  1103,  1226,    30,  1140,  1150,   103,  1123,\n",
      "         1111,  1217,   170, 21803,   113,  5931,   114,   117,  1103,\n",
      "           37,   103,  1119,  3683,  1119,  1125,   117,  1103,  9207,\n",
      "         1401,  1119,  3683,  1119,  1125,   117,  1103, 15589,   103,\n",
      "         1104,  1471,   113,  3647,   103,   117,  1103,   103,  1226,\n",
      "         1104,   102],\n",
      "       [  101,   146,  1450,  1164,  1142,  1273,  1263,  1196,   146,\n",
      "         1486,  1122,   119,   103,  1864,   117,   146,  1125,  1106,\n",
      "          103,  1103,  4173,  1107,  1546,  1106,  1267,  1122,  1272,\n",
      "         1185,  1888,  2984,  2446,   103,   119,   146,  1238,   112,\n",
      "          189,  1713,   103,  1103,   109,  1367,  1106,  4417,  1122,\n",
      "         1215,  1272,   103,  7822,  1228,  1103,  2095,  5558,   119,\n",
      "         1109,  1207,  2609,  2596,  2702,  4173,  1144,  1632,  1839,\n",
      "         1105, 19924,  1136,  2213,   119,   146,  1276,  1991,  5574,\n",
      "         1277,  1167,  1173,   133,  9304,   120,   135,   133,  9304,\n",
      "          120,   135, 26078,  1158,  1107,  2945,   103,  1780,  1175,\n",
      "          103,   170,  1374,  4429,  1127,   146,    85, 10057,   119,\n",
      "          103,   103,   120,   103,   133,  9304,   120,   135,  1409,\n",
      "         1128,  5548,  1228,  1103,  2095, 19025,   188,  6617,   118,\n",
      "          103,   120,  5367,   103,   117,  1128,  1930,  1209,  3940,\n",
      "         1142,   102],\n",
      "       [  101,  1188,  2523,  1110,  1541,   103,  9684,   119,  1135,\n",
      "          112,   188,  1112,  2213,  1112, 25249,  3078,  1218,  2654,\n",
      "          103,  1115,  2213,   103,  2785,  1601,   119,  1409,  1240,\n",
      "          170,  5442,  1104,  1103,  2169,   103,  5558,    40,  1128,\n",
      "         1547,  1176,  1142,  2523,   119,   146,  1354,   103,  1122,\n",
      "         1108,  6961,  1485,  8362, 21200,   103,  1104,  1736,   146,\n",
      "          112,   182,  1136,   170,  5442,  1104,  1103,  2169,  5558,\n",
      "          119,   103,   103,  2169,  2523,   103,  1108,   103,  1108,\n",
      "        17009, 16358, 27089, 25134,  1204,   119,  5979,  1110,   103,\n",
      "         1166,  5894,  2523,   119,  1188,  1273,   103,  1236,  1166,\n",
      "         5894,   119,  1252,  1519,   112,   188,  1243,  1408,  1114,\n",
      "         1293,  9210,  1142,  1273,  1541,  1110,  4103,  1195,   119,\n",
      "         1109,  3176,  1110,  1301,   103,  1183,  1105,  9210,   119,\n",
      "         1109,  3154,   103,   119,   103,  4928,   103,  1142,  2523,\n",
      "          103,   102],\n",
      "       [  101,  7911,   103,  2517,   119,   119,   119,  4208,   146,\n",
      "         1202,   119,   133,  9304,   120,   135,   133,    49,   120,\n",
      "          103,  1109,  1900,  1104,   112,   103, 24479,  1181,   112,\n",
      "         1144,  5544,  1562,  6050, 13896, 18331,   112,   188,   112,\n",
      "          103,   112,   170,  1374,   103,   103,  1551,  1105,   103,\n",
      "         1471,  1103,  2304,   117,   103,  1409,   112,  3524,   103,\n",
      "         1125,  1151,  1126,  5178,   118, 10187,  8144,  1164,  6039,\n",
      "         1107,  1103,  1485,  2174,   117,  1184,  1156,  1122,  1129,\n",
      "         1176,   136,   107,  2119,   117,   146,   112,  1325,  1587,\n",
      "        11078,   117,  1122,   103,   173,  1129,  1176,  5539,  1904,\n",
      "         1104,   170,   103, 20239, 10710,  1128,   103,  1103, 22106,\n",
      "          117,   103,  1136,  1112, 18330,   119,  1109,   103,  1108,\n",
      "        19498,  1114,   176,   103, 10950,  2285,  9188,  1734,  1105,\n",
      "          189, 10587,  1141,   118, 12119,  1116,   117,  1105, 11830,\n",
      "         5045,   102],\n",
      "       [  101,  1188,  1110,  1103,  2076,  1104,  2523,  1115,   112,\n",
      "          188,  1198,   103,  5336,  1536,  1111,  1141, 10761,   117,\n",
      "         1133,   146,   103,   103,    51,  1341,   146,  1180,  2484,\n",
      "         1106,  2824,   103,  1254,   119,  1135,  2736,  1105,  2399,\n",
      "         1176,   170,  2286,   118,  5334,  4338,  1794,  2523,   117,\n",
      "         1178,  1114,  1199,   103,  7625, 10950,   103,  2673,   103,\n",
      "         4289,  6358,  1107,   119,   133,  9304,   120,   103,   133,\n",
      "         9304,   120,   135,   146,  5340,  1114,  1317,  2166, 16300,\n",
      "          118,   103,  1430,   103, 26119,  7147,   103,  1110, 24819,\n",
      "         1942,   103, 27242,   117,  1105,    25,  1551,  1256,  2502,\n",
      "         1228,  1112,  8362, 10879, 15399,   103,   119,  1335,  1655,\n",
      "         1103,  1168,  1160, 20246,  1294,  1146,  1111,  1115,   119,\n",
      "         2907,   117,  1122,  1108, 26078,  1158,  1106,  1267,  4947,\n",
      "        13359,  2386,  1110,  1216,    30, 16270,  1648,   117,  1134,\n",
      "         5397,   102]], dtype=int32)>, 'input_type_ids': <tf.Tensor: shape=(5, 128), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "      dtype=int32)>, 'input_mask': <tf.Tensor: shape=(5, 128), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "      dtype=int32)>, 'masked_lm_positions': <tf.Tensor: shape=(5, 17), dtype=int32, numpy=\n",
      "array([[ 14,  22,  30,  31,  40,  45,  47,  51,  63,  68,  80,  88, 100,\n",
      "        116, 121, 124,   0],\n",
      "       [ 12,  18,  31,  38,  47,  87,  90,  99, 100, 102, 117, 120,   0,\n",
      "          0,   0,   0,   0],\n",
      "       [  5,  18,  21,  32,  43,  50,  64,  65,  68,  70,  80,  87, 112,\n",
      "        119, 121, 123, 126],\n",
      "       [  2,  18,  23,  36,  40,  41,  44,  49,  53,  84,  92,  96, 100,\n",
      "        106, 111,   0,   0],\n",
      "       [ 11,  20,  21,  29,  48,  51,  53,  61,  73,  75,  78,  82,  95,\n",
      "          0,   0,   0,   0]], dtype=int32)>} {'masked_lm_labels': <tf.Tensor: shape=(5, 17), dtype=int32, numpy=\n",
      "array([[13336,   170,  1395,   119,  1106,  1152,   112,  1561, 13497,\n",
      "         6202,  1204,  5687,  1534,  1226,   114,  5973,   101],\n",
      "       [ 1130,  4417,  1122,  5369,   146,   117,  1127,   133,  9304,\n",
      "          135, 20497,  5558,   101,   101,   101,   101,   101],\n",
      "       [ 1541,  1136,  1133,  5367,  1115,  1895,  1109,  1178,  1115,\n",
      "        10899,  1141,  1110, 10008, 13054,  1302,  1114,   119],\n",
      "       [  170,   135,  1109,  3524,  1315,  1242,  1455,   107,   112,\n",
      "          112,  3619,  1107,  1178,  8556,  7625,   101,   101],\n",
      "       [ 3742,  1274,   112,  1122,   176,  2285,  1105,   135,   118,\n",
      "         2707,  3708,  1304,  3789,   101,   101,   101,   101]],\n",
      "      dtype=int32)>, 'masked_lm_mask': <tf.Tensor: shape=(5, 17), dtype=float32, numpy=\n",
      "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0.]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for (batch_inputs, batch_labels) in dataset_unsupervised.take(1):\n",
    "    print(batch_inputs, batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c92bdc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "f9cf3253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers.models import BertModel\n",
    "from tf_transformers.losses import cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "4cedd185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successful: Model checkpoints matched and loaded from /tmp/tf_transformers_cache/bert-base-cased\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-cased'\n",
    "model, config = BertModel.get_model(model_name=model_name,\n",
    "                                    use_masked_lm_positions=True,\n",
    "                                    return_all_layer_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "021041bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <KerasTensor: shape=(None, None) dtype=int32 (created by layer 'input_ids')>,\n",
       " 'input_mask': <KerasTensor: shape=(None, None) dtype=int32 (created by layer 'input_mask')>,\n",
       " 'input_type_ids': <KerasTensor: shape=(None, None) dtype=int32 (created by layer 'input_type_ids')>,\n",
       " 'masked_lm_positions': <KerasTensor: shape=(None, None) dtype=int32 (created by layer 'masked_lm_positions')>}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "74c8e374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls_output': <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       " 'token_embeddings': <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       " 'token_logits': <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       " 'last_token_logits': <KerasTensor: shape=(None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       " 'all_layer_token_embeddings': [<KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>],\n",
       " 'all_layer_cls_output': [<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_transformers/bert')>],\n",
       " 'all_layer_token_logits': [<KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>,\n",
       "  <KerasTensor: shape=(None, None, 28996) dtype=float32 (created by layer 'tf_transformers/bert')>]}"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "aecff3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = model(batch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "1fb1cee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[ 0.6364071 ,  0.39737868, -0.09157881, ...,  0.34175146,\n",
       "           0.5136198 , -0.78899205],\n",
       "         [-0.06405342,  0.44488218,  0.09692273, ...,  0.3577524 ,\n",
       "           0.01640294, -0.48131403],\n",
       "         [ 0.02143574,  0.16771254, -0.10223933, ..., -0.44842073,\n",
       "          -0.3124991 , -0.39341444],\n",
       "         ...,\n",
       "         [ 0.10923192,  0.46006092,  0.51024324, ...,  0.14270039,\n",
       "          -0.16740501, -0.6073307 ],\n",
       "         [ 0.3565812 ,  0.2618315 ,  1.0749931 , ...,  0.11836857,\n",
       "          -0.02579454, -0.8573086 ],\n",
       "         [-0.6148638 ,  0.6964495 , -0.4577043 , ...,  0.3505425 ,\n",
       "           0.25855872, -0.96123344]],\n",
       " \n",
       "        [[ 0.6176162 ,  0.7161437 ,  0.6636988 , ...,  0.37515405,\n",
       "           0.3667674 , -0.5562779 ],\n",
       "         [-0.08186221,  0.58370185,  0.04298308, ...,  0.10876828,\n",
       "          -0.6345585 , -0.6571902 ],\n",
       "         [ 0.31409347,  0.4121155 ,  0.10250878, ...,  0.18999144,\n",
       "          -0.12050951, -0.36112264],\n",
       "         ...,\n",
       "         [-0.6234829 ,  0.6879194 , -0.45545864, ...,  0.3529152 ,\n",
       "           0.2535609 , -0.9531485 ],\n",
       "         [-0.6234829 ,  0.6879194 , -0.45545864, ...,  0.3529152 ,\n",
       "           0.2535609 , -0.9531485 ],\n",
       "         [-0.6234829 ,  0.6879194 , -0.45545864, ...,  0.3529152 ,\n",
       "           0.2535609 , -0.9531485 ]],\n",
       " \n",
       "        [[-0.01749074,  0.6109765 ,  0.578738  , ..., -0.6195185 ,\n",
       "          -0.5737145 , -0.5483254 ],\n",
       "         [-0.08866966,  0.58495486,  0.03789455, ...,  0.10670827,\n",
       "          -0.6337391 , -0.66512424],\n",
       "         [ 0.47508585,  0.64119476, -0.08005619, ..., -0.33881843,\n",
       "          -0.74116504, -0.16085137],\n",
       "         ...,\n",
       "         [ 0.08965665,  0.46617216,  0.5018463 , ...,  0.13104957,\n",
       "          -0.17613176, -0.6127749 ],\n",
       "         [ 0.26273686,  0.7458089 , -0.17435583, ...,  0.51622146,\n",
       "          -0.43833283, -0.5077365 ],\n",
       "         [ 0.55002785,  0.4712267 ,  0.33720875, ...,  0.09753814,\n",
       "           0.1328151 , -0.51969665]],\n",
       " \n",
       "        [[ 0.3696993 ,  0.2324548 ,  0.27093768, ..., -0.19302186,\n",
       "          -0.23289558, -0.01605654],\n",
       "         [-0.07595366,  0.58328706,  0.04413205, ...,  0.11428046,\n",
       "          -0.6335285 , -0.66531414],\n",
       "         [ 0.48701948,  0.61494195, -0.2109004 , ..., -0.5240197 ,\n",
       "          -0.34249166, -1.2837248 ],\n",
       "         ...,\n",
       "         [ 0.03342676,  0.651968  , -0.05206829, ...,  0.82476926,\n",
       "          -0.18042791, -0.56685156],\n",
       "         [-0.6264744 ,  0.6941873 , -0.45978203, ...,  0.35384053,\n",
       "           0.2502823 , -0.9568975 ],\n",
       "         [-0.6264744 ,  0.6941873 , -0.45978203, ...,  0.35384053,\n",
       "           0.2502823 , -0.9568975 ]],\n",
       " \n",
       "        [[ 0.24467504,  0.3812787 ,  0.11489297, ...,  0.22451621,\n",
       "           0.32602412, -0.5688197 ],\n",
       "         [ 0.05936056,  0.30847964, -0.60428435, ..., -0.16124961,\n",
       "          -0.17743775, -0.30139548],\n",
       "         [ 0.47226256,  0.6309658 , -0.07133582, ..., -0.32128567,\n",
       "          -0.7364458 , -0.1463294 ],\n",
       "         ...,\n",
       "         [-0.635395  ,  0.6890934 , -0.46233773, ...,  0.35531473,\n",
       "           0.24902353, -0.9515132 ],\n",
       "         [-0.635395  ,  0.6890934 , -0.46233773, ...,  0.35531473,\n",
       "           0.24902353, -0.9515132 ],\n",
       "         [-0.63539505,  0.6890937 , -0.46233755, ...,  0.35531446,\n",
       "           0.24902335, -0.95151293]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[ 0.37404484,  0.0228582 , -0.09348983, ...,  0.33374402,\n",
       "           0.399572  , -0.87620854],\n",
       "         [-0.00634888,  0.18820047, -0.12663116, ...,  0.57379496,\n",
       "          -0.01765636, -0.36629024],\n",
       "         [ 0.06653339,  0.17192447, -0.2173655 , ..., -0.60297126,\n",
       "          -0.25647163, -0.26442868],\n",
       "         ...,\n",
       "         [ 0.4385649 ,  0.23242047,  0.08425772, ...,  0.22312784,\n",
       "          -0.30302137, -0.6284342 ],\n",
       "         [ 0.5464545 , -0.05665296,  0.5566904 , ...,  0.13886356,\n",
       "          -0.21160059, -0.37563506],\n",
       "         [-0.1431144 ,  0.54664   , -0.28902933, ...,  0.47075498,\n",
       "          -0.10334781, -0.9100489 ]],\n",
       " \n",
       "        [[ 0.75734365,  0.30752087,  0.6878539 , ...,  0.32091823,\n",
       "           0.141144  , -0.4823264 ],\n",
       "         [ 0.10316965,  0.30663612, -0.19393373, ...,  0.18067002,\n",
       "          -0.6780924 , -0.6590659 ],\n",
       "         [ 0.56634223,  0.11848333, -0.0913052 , ...,  0.08075798,\n",
       "          -0.12125576, -0.39052323],\n",
       "         ...,\n",
       "         [-0.15578702,  0.5279838 , -0.28747997, ...,  0.46269482,\n",
       "          -0.10297078, -0.8903081 ],\n",
       "         [-0.15578702,  0.5279838 , -0.28747997, ...,  0.46269482,\n",
       "          -0.10297078, -0.8903081 ],\n",
       "         [-0.15578702,  0.5279838 , -0.28747997, ...,  0.46269482,\n",
       "          -0.10297078, -0.8903081 ]],\n",
       " \n",
       "        [[ 0.21058667,  0.1149095 ,  0.55442536, ..., -0.6893889 ,\n",
       "          -0.6249261 , -0.6801316 ],\n",
       "         [ 0.09301984,  0.31746307, -0.19385225, ...,  0.18226513,\n",
       "          -0.6833879 , -0.67207944],\n",
       "         [ 0.25916928,  0.359349  , -0.14247176, ..., -0.44660708,\n",
       "          -0.49027583, -0.09956333],\n",
       "         ...,\n",
       "         [ 0.41320276,  0.25137615,  0.09501132, ...,  0.21967769,\n",
       "          -0.30816954, -0.6361872 ],\n",
       "         [ 0.3870883 ,  0.2978472 , -0.28043544, ...,  0.3656887 ,\n",
       "          -0.5048192 , -0.31506848],\n",
       "         [ 0.5053703 ,  0.47098893,  0.20081446, ..., -0.098644  ,\n",
       "          -0.20721161, -0.14714703]],\n",
       " \n",
       "        [[ 0.37491387, -0.04744035, -0.08336329, ..., -0.27798378,\n",
       "          -0.42786917,  0.23574534],\n",
       "         [ 0.10464266,  0.31341156, -0.19317026, ...,  0.18317789,\n",
       "          -0.67783797, -0.6755226 ],\n",
       "         [ 0.6000712 ,  0.33260378, -0.41559353, ..., -0.52475464,\n",
       "          -0.13457291, -1.2993613 ],\n",
       "         ...,\n",
       "         [ 0.16447742,  0.3838667 , -0.29831594, ...,  0.77483106,\n",
       "          -0.47412112, -0.30572346],\n",
       "         [-0.15970895,  0.54464436, -0.30210543, ...,  0.47057337,\n",
       "          -0.10755107, -0.90672666],\n",
       "         [-0.15970895,  0.54464436, -0.30210543, ...,  0.47057337,\n",
       "          -0.10755107, -0.90672666]],\n",
       " \n",
       "        [[-0.00131691,  0.04659659, -0.07752702, ...,  0.23737076,\n",
       "           0.23214367, -0.54174984],\n",
       "         [-0.01175582,  0.09678525, -0.77418494, ..., -0.19962306,\n",
       "          -0.30230376, -0.26811868],\n",
       "         [ 0.261652  ,  0.3508988 , -0.13755617, ..., -0.44573876,\n",
       "          -0.48398757, -0.08237714],\n",
       "         ...,\n",
       "         [-0.16485259,  0.53786886, -0.29557368, ...,  0.46076858,\n",
       "          -0.10804206, -0.8971311 ],\n",
       "         [-0.16485259,  0.53786886, -0.29557368, ...,  0.46076858,\n",
       "          -0.10804206, -0.8971311 ],\n",
       "         [-0.1648527 ,  0.5378687 , -0.2955742 , ...,  0.4607687 ,\n",
       "          -0.10804263, -0.89713097]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[-0.06937701,  0.1530304 , -0.56480354, ...,  0.08019219,\n",
       "           0.06344654, -0.3749474 ],\n",
       "         [-0.5163481 ,  0.7400944 , -0.17512189, ...,  0.4666046 ,\n",
       "          -0.1209328 ,  0.1609252 ],\n",
       "         [-0.26043636,  0.62125945, -0.31760764, ..., -0.6622666 ,\n",
       "          -0.13563964, -0.04790837],\n",
       "         ...,\n",
       "         [-0.42121434,  0.6620216 , -0.13291101, ...,  0.03542942,\n",
       "          -0.1318843 , -0.21189906],\n",
       "         [ 0.3158043 ,  0.28368264,  0.45421782, ...,  0.03497446,\n",
       "          -0.0699922 , -0.08013977],\n",
       "         [-0.42129347,  0.32863963,  0.04526602, ...,  0.33875275,\n",
       "          -0.17022592, -0.87994415]],\n",
       " \n",
       "        [[ 0.02701077,  0.714249  ,  0.49164173, ..., -0.2283018 ,\n",
       "          -0.0172819 ,  0.24228498],\n",
       "         [-0.28135192,  0.35052615, -0.1211715 , ..., -0.10025127,\n",
       "          -0.62515444, -0.19071683],\n",
       "         [ 0.05066231,  0.58502686, -0.03373992, ..., -0.18798739,\n",
       "          -0.21718034, -0.1982283 ],\n",
       "         ...,\n",
       "         [-0.42592785,  0.30053693,  0.04604428, ...,  0.34387594,\n",
       "          -0.16084394, -0.86604184],\n",
       "         [-0.42592785,  0.30053693,  0.04604428, ...,  0.34387594,\n",
       "          -0.16084394, -0.86604184],\n",
       "         [-0.42592785,  0.30053693,  0.04604428, ...,  0.34387594,\n",
       "          -0.16084394, -0.86604184]],\n",
       " \n",
       "        [[-0.11758322,  0.33216873, -0.07198006, ..., -0.4428103 ,\n",
       "          -0.18395865, -0.71718836],\n",
       "         [-0.29567152,  0.3641286 , -0.11301327, ..., -0.10435529,\n",
       "          -0.6214963 , -0.18484099],\n",
       "         [-0.09799105,  0.6137429 , -0.17335275, ..., -0.4150567 ,\n",
       "          -0.6987984 ,  0.40866154],\n",
       "         ...,\n",
       "         [-0.4540372 ,  0.6804379 , -0.12146018, ...,  0.03090358,\n",
       "          -0.10978105, -0.20192318],\n",
       "         [ 0.05652666,  0.5841533 , -0.55762714, ...,  0.26863134,\n",
       "          -0.49632716, -0.07690975],\n",
       "         [ 0.17938754,  0.80175745, -0.10350856, ..., -0.14862621,\n",
       "          -0.23337805,  0.13720898]],\n",
       " \n",
       "        [[ 0.02979884,  0.4294155 , -0.32421842, ..., -0.6902751 ,\n",
       "          -0.23960042,  0.4917925 ],\n",
       "         [-0.2794491 ,  0.35727555, -0.11645355, ..., -0.1134977 ,\n",
       "          -0.63107586, -0.19720817],\n",
       "         [ 0.34027773,  0.62142676, -0.29580563, ..., -0.51755655,\n",
       "          -0.35083845, -0.9153757 ],\n",
       "         ...,\n",
       "         [ 0.00669344,  0.69920516, -0.22545671, ...,  0.51819146,\n",
       "          -0.39110398,  0.09533129],\n",
       "         [-0.43477863,  0.3242626 ,  0.04478875, ...,  0.34053802,\n",
       "          -0.16809896, -0.8699902 ],\n",
       "         [-0.43477863,  0.3242626 ,  0.04478875, ...,  0.34053802,\n",
       "          -0.16809896, -0.8699902 ]],\n",
       " \n",
       "        [[-0.33505574,  0.49589097, -0.34231082, ...,  0.02029562,\n",
       "           0.12896845, -0.32320112],\n",
       "         [-0.11941454,  0.44704223, -0.89487493, ..., -0.43887684,\n",
       "          -0.25169787, -0.17237434],\n",
       "         [-0.08186996,  0.6124425 , -0.17150234, ..., -0.41927975,\n",
       "          -0.71734387,  0.41577992],\n",
       "         ...,\n",
       "         [-0.42578483,  0.3132723 ,  0.04268277, ...,  0.3313737 ,\n",
       "          -0.1665737 , -0.8584116 ],\n",
       "         [-0.42578483,  0.3132723 ,  0.04268277, ...,  0.3313737 ,\n",
       "          -0.1665737 , -0.8584116 ],\n",
       "         [-0.4257845 ,  0.31327206,  0.04268321, ...,  0.3313737 ,\n",
       "          -0.1665738 , -0.8584118 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[-0.08621472,  0.11571413, -0.32288313, ...,  0.2668236 ,\n",
       "           0.04926464, -0.2780136 ],\n",
       "         [-0.26539335,  0.6292519 ,  0.07036319, ...,  0.22615206,\n",
       "           0.06713676,  0.20573425],\n",
       "         [-0.53372896,  0.6437621 , -0.3177758 , ..., -0.3701387 ,\n",
       "          -0.02638486,  0.20855163],\n",
       "         ...,\n",
       "         [-0.3400072 ,  0.6120182 , -0.11190364, ...,  0.11244208,\n",
       "          -0.07271056, -0.19452113],\n",
       "         [ 0.24678941,  0.07146764,  0.42202199, ...,  0.15188499,\n",
       "           0.290707  , -0.22833326],\n",
       "         [-0.2191821 ,  0.25893316,  0.30372396, ...,  0.05571613,\n",
       "          -0.4002861 , -0.72325325]],\n",
       " \n",
       "        [[-0.09411442,  0.5646958 ,  0.516598  , ..., -0.3085901 ,\n",
       "          -0.05166861,  0.47004655],\n",
       "         [ 0.00313321,  0.36282077,  0.21369565, ..., -0.16325335,\n",
       "          -0.90656114, -0.13607596],\n",
       "         [ 0.18324734,  0.29160652,  0.23894295, ..., -0.09530844,\n",
       "          -0.17532805, -0.04814324],\n",
       "         ...,\n",
       "         [-0.21367235,  0.23292863,  0.27799007, ...,  0.05683297,\n",
       "          -0.38843414, -0.700724  ],\n",
       "         [-0.21367235,  0.23292863,  0.27799007, ...,  0.05683297,\n",
       "          -0.38843414, -0.700724  ],\n",
       "         [-0.21367235,  0.23292863,  0.27799007, ...,  0.05683297,\n",
       "          -0.38843414, -0.700724  ]],\n",
       " \n",
       "        [[-0.12683874,  0.41595465,  0.23995173, ..., -0.31062222,\n",
       "           0.01326241, -0.7139191 ],\n",
       "         [-0.03043905,  0.37919068,  0.2163837 , ..., -0.14927822,\n",
       "          -0.91232926, -0.15066975],\n",
       "         [-0.173498  ,  0.7685132 ,  0.02297692, ..., -0.45958948,\n",
       "          -0.8599635 ,  0.31406385],\n",
       "         ...,\n",
       "         [-0.3717338 ,  0.6408299 , -0.1165736 , ...,  0.11533028,\n",
       "          -0.06863001, -0.19640015],\n",
       "         [ 0.19997153,  0.57685876, -0.39513278, ...,  0.06429569,\n",
       "          -0.14394999, -0.29153764],\n",
       "         [ 0.3636953 ,  0.8074745 ,  0.29081804, ..., -0.32681978,\n",
       "          -0.02180461, -0.0763815 ]],\n",
       " \n",
       "        [[ 0.18171038,  0.38270923, -0.16257621, ..., -0.21600813,\n",
       "          -0.20465308,  0.6635907 ],\n",
       "         [-0.01050425,  0.3632235 ,  0.21685408, ..., -0.15947488,\n",
       "          -0.9182136 , -0.13919719],\n",
       "         [ 0.40816143,  0.4866278 , -0.30674842, ..., -0.47771803,\n",
       "          -0.24636698, -0.63363785],\n",
       "         ...,\n",
       "         [ 0.24736007,  0.37174988, -0.02054042, ...,  0.2990135 ,\n",
       "          -0.46913642,  0.26358727],\n",
       "         [-0.22165777,  0.24924347,  0.2844866 , ...,  0.06258035,\n",
       "          -0.39705   , -0.7052774 ],\n",
       "         [-0.22165777,  0.24924347,  0.2844866 , ...,  0.06258035,\n",
       "          -0.39705   , -0.7052774 ]],\n",
       " \n",
       "        [[-0.10964352,  0.42865092, -0.30691898, ...,  0.15660524,\n",
       "           0.26176357, -0.5363176 ],\n",
       "         [-0.1988824 ,  0.3680249 , -0.6035507 , ..., -0.05720244,\n",
       "          -0.15173583, -0.25731915],\n",
       "         [-0.15431494,  0.7693194 ,  0.02869628, ..., -0.46690732,\n",
       "          -0.87210786,  0.3210659 ],\n",
       "         ...,\n",
       "         [-0.21352613,  0.23359647,  0.28542447, ...,  0.04623577,\n",
       "          -0.39863482, -0.7005564 ],\n",
       "         [-0.21352613,  0.23359647,  0.28542447, ...,  0.04623577,\n",
       "          -0.39863482, -0.7005564 ],\n",
       "         [-0.21352607,  0.2335965 ,  0.28542492, ...,  0.04623577,\n",
       "          -0.39863464, -0.7005565 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[ 4.44299579e-02,  3.15535456e-01, -4.31964874e-01, ...,\n",
       "          -2.58404732e-01,  3.24026197e-01,  2.08116338e-01],\n",
       "         [-3.64383519e-01,  5.27540922e-01, -1.28848106e-03, ...,\n",
       "          -8.27226043e-02,  1.68595076e-01,  5.42877436e-01],\n",
       "         [-1.63833916e-01,  7.83301473e-01, -3.40681970e-01, ...,\n",
       "          -6.55560315e-01,  2.25923404e-01,  5.39284825e-01],\n",
       "         ...,\n",
       "         [-2.70089805e-01,  8.34814191e-01, -1.10937402e-01, ...,\n",
       "          -1.61493734e-01, -1.02174282e-03,  1.40877381e-01],\n",
       "         [ 2.46124774e-01,  5.52650392e-01,  2.38143563e-01, ...,\n",
       "          -1.37176007e-01,  4.35218662e-01,  5.59275150e-02],\n",
       "         [-4.34702218e-01,  3.88747156e-01,  1.16303831e-01, ...,\n",
       "           4.22715545e-02, -3.03058118e-01, -5.15127599e-01]],\n",
       " \n",
       "        [[-2.29523569e-01,  7.28078961e-01,  3.46133232e-01, ...,\n",
       "          -7.01137304e-01,  3.05612832e-01,  9.57714856e-01],\n",
       "         [-9.32230353e-02,  3.94853026e-01, -1.20514877e-01, ...,\n",
       "          -3.47370148e-01, -8.31929326e-01,  3.83179814e-01],\n",
       "         [ 1.14142895e-04,  4.09318924e-01,  6.87606037e-02, ...,\n",
       "          -4.75598395e-01, -4.70164791e-02,  3.33862305e-01],\n",
       "         ...,\n",
       "         [-4.21809494e-01,  3.63350540e-01,  8.86547565e-02, ...,\n",
       "           3.83023024e-02, -3.02928150e-01, -4.96748447e-01],\n",
       "         [-4.21809494e-01,  3.63350540e-01,  8.86547565e-02, ...,\n",
       "           3.83023024e-02, -3.02928150e-01, -4.96748447e-01],\n",
       "         [-4.21809494e-01,  3.63350540e-01,  8.86547565e-02, ...,\n",
       "           3.83023024e-02, -3.02928150e-01, -4.96748447e-01]],\n",
       " \n",
       "        [[-1.44071758e-01,  6.41514778e-01,  2.62264639e-01, ...,\n",
       "          -5.54302812e-01,  4.81534153e-02, -4.85768020e-01],\n",
       "         [-1.12750113e-01,  4.09275353e-01, -1.38024673e-01, ...,\n",
       "          -3.29972774e-01, -8.39497030e-01,  3.91763598e-01],\n",
       "         [-2.12263227e-01,  8.88696969e-01,  7.19483644e-02, ...,\n",
       "          -6.62328124e-01, -8.15258741e-01,  4.37320352e-01],\n",
       "         ...,\n",
       "         [-2.94172466e-01,  8.72676015e-01, -1.06071770e-01, ...,\n",
       "          -1.66602463e-01, -9.77834314e-03,  1.49206519e-01],\n",
       "         [ 5.61251044e-02,  6.70213342e-01, -2.33209699e-01, ...,\n",
       "          -1.11640289e-01, -1.27269030e-02, -1.23648196e-01],\n",
       "         [ 3.35449934e-01,  1.06913650e+00,  1.62361607e-01, ...,\n",
       "          -3.23133975e-01,  1.07345536e-01,  1.99175745e-01]],\n",
       " \n",
       "        [[ 1.05190486e-01,  3.72197151e-01, -1.06845364e-01, ...,\n",
       "          -3.91264737e-01, -1.80141866e-01,  9.15327013e-01],\n",
       "         [-9.80519652e-02,  4.01687086e-01, -1.35701820e-01, ...,\n",
       "          -3.27365279e-01, -8.48774314e-01,  3.90254557e-01],\n",
       "         [ 3.58353138e-01,  6.72359884e-01, -3.55544925e-01, ...,\n",
       "          -7.21672714e-01, -1.68070883e-01, -5.13016820e-01],\n",
       "         ...,\n",
       "         [ 2.53342688e-01,  7.79444814e-01, -1.20891005e-01, ...,\n",
       "          -2.29211003e-02, -4.25874203e-01,  6.53354049e-01],\n",
       "         [-4.31033194e-01,  3.83026272e-01,  8.96760970e-02, ...,\n",
       "           5.81647754e-02, -3.11529338e-01, -4.91100490e-01],\n",
       "         [-4.31033194e-01,  3.83026272e-01,  8.96760970e-02, ...,\n",
       "           5.81647754e-02, -3.11529338e-01, -4.91100490e-01]],\n",
       " \n",
       "        [[ 1.04595125e-01,  4.54573691e-01, -5.87224364e-01, ...,\n",
       "          -3.09848905e-01,  3.50157499e-01, -1.58901066e-01],\n",
       "         [-6.48850203e-03,  5.01372397e-01, -8.93622994e-01, ...,\n",
       "          -1.90010503e-01, -1.28013477e-01,  9.89624932e-02],\n",
       "         [-2.03589022e-01,  8.96501601e-01,  7.28964955e-02, ...,\n",
       "          -6.65139437e-01, -8.34099889e-01,  4.35909957e-01],\n",
       "         ...,\n",
       "         [-4.17780101e-01,  3.69768769e-01,  9.03974921e-02, ...,\n",
       "           3.94856632e-02, -3.16441208e-01, -4.95548368e-01],\n",
       "         [-4.17780101e-01,  3.69768769e-01,  9.03974921e-02, ...,\n",
       "           3.94856632e-02, -3.16441208e-01, -4.95548368e-01],\n",
       "         [-4.17779952e-01,  3.69768947e-01,  9.03978050e-02, ...,\n",
       "           3.94858420e-02, -3.16441447e-01, -4.95548040e-01]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[ 0.201338  ,  0.5056473 , -0.39239377, ..., -0.23056048,\n",
       "           0.0369685 ,  0.14080769],\n",
       "         [-0.27996063,  0.76372135, -0.04838355, ...,  0.01309594,\n",
       "          -0.11437303,  0.4330229 ],\n",
       "         [-0.05285013,  0.91569424, -0.3838909 , ..., -0.38670105,\n",
       "           0.34796637,  0.5772394 ],\n",
       "         ...,\n",
       "         [ 0.12523359,  0.69128555, -0.14404175, ...,  0.09757838,\n",
       "           0.01794156, -0.01247442],\n",
       "         [ 0.40676954,  0.6133213 ,  0.34967452, ..., -0.1868543 ,\n",
       "           0.40200597,  0.02375378],\n",
       "         [-0.15504073,  0.48215955, -0.1755731 , ...,  0.25017643,\n",
       "          -0.00710274, -0.40481395]],\n",
       " \n",
       "        [[-0.14103687,  0.97026974,  0.11632476, ..., -0.55166966,\n",
       "          -0.04094724,  0.9865842 ],\n",
       "         [-0.1285654 ,  0.4160509 , -0.33531007, ..., -0.02546692,\n",
       "          -1.02718   ,  0.37212768],\n",
       "         [ 0.03304267,  0.59132457,  0.08170046, ..., -0.4510751 ,\n",
       "          -0.19450419,  0.12787944],\n",
       "         ...,\n",
       "         [-0.15499957,  0.46017984, -0.1897805 , ...,  0.2550361 ,\n",
       "          -0.00830226, -0.3844408 ],\n",
       "         [-0.15499957,  0.46017984, -0.1897805 , ...,  0.2550361 ,\n",
       "          -0.00830226, -0.3844408 ],\n",
       "         [-0.15499957,  0.46017984, -0.1897805 , ...,  0.2550361 ,\n",
       "          -0.00830226, -0.3844408 ]],\n",
       " \n",
       "        [[ 0.00163153,  0.6080898 ,  0.12650321, ..., -0.5240854 ,\n",
       "          -0.03009301, -0.6807205 ],\n",
       "         [-0.14813602,  0.4249316 , -0.33415464, ..., -0.009332  ,\n",
       "          -1.027498  ,  0.3489204 ],\n",
       "         [ 0.07325077,  0.93699485,  0.10174386, ..., -0.69424665,\n",
       "          -0.854914  ,  0.37960872],\n",
       "         ...,\n",
       "         [ 0.1133852 ,  0.71592224, -0.13340904, ...,  0.09761919,\n",
       "           0.00550677, -0.03758401],\n",
       "         [ 0.0308376 ,  0.633481  , -0.43343   , ...,  0.04924929,\n",
       "          -0.18846531,  0.18997988],\n",
       "         [ 0.35620606,  0.97111034, -0.17148864, ..., -0.07544799,\n",
       "           0.06109306,  0.16069461]],\n",
       " \n",
       "        [[ 0.00619808,  0.60828245, -0.06937534, ..., -0.3794518 ,\n",
       "          -0.29714304,  0.9720508 ],\n",
       "         [-0.13400042,  0.43302003, -0.3392599 , ..., -0.0165914 ,\n",
       "          -1.044693  ,  0.3570648 ],\n",
       "         [ 0.23987152,  0.72353995, -0.34755346, ..., -0.6538064 ,\n",
       "          -0.35398865, -0.4891348 ],\n",
       "         ...,\n",
       "         [ 0.2356664 ,  1.110623  , -0.00410709, ...,  0.0619055 ,\n",
       "          -0.6258726 ,  0.86471343],\n",
       "         [-0.1474678 ,  0.4817614 , -0.1953247 , ...,  0.2649442 ,\n",
       "          -0.02283651, -0.38296998],\n",
       "         [-0.1474678 ,  0.4817614 , -0.1953247 , ...,  0.2649442 ,\n",
       "          -0.02283651, -0.38296998]],\n",
       " \n",
       "        [[ 0.06096745,  0.72597456, -0.43494678, ..., -0.06574628,\n",
       "           0.10836352, -0.02305995],\n",
       "         [ 0.1647417 ,  0.79369855, -0.79802895, ...,  0.03159897,\n",
       "          -0.1769909 ,  0.28197908],\n",
       "         [ 0.06898126,  0.9475593 ,  0.08593734, ..., -0.6899637 ,\n",
       "          -0.8790659 ,  0.40141797],\n",
       "         ...,\n",
       "         [-0.13995136,  0.45951512, -0.19336052, ...,  0.25436762,\n",
       "          -0.01741185, -0.3856439 ],\n",
       "         [-0.13995136,  0.45951512, -0.19336052, ...,  0.25436762,\n",
       "          -0.01741185, -0.3856439 ],\n",
       "         [-0.13995129,  0.4595148 , -0.19336039, ...,  0.2543679 ,\n",
       "          -0.01741194, -0.38564402]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[-0.14466289,  0.83923846, -0.09147297, ..., -0.09461322,\n",
       "          -0.12982339,  0.29036567],\n",
       "         [-0.7338536 ,  1.13586   , -0.10802005, ...,  0.08678022,\n",
       "          -0.18398674,  0.32872105],\n",
       "         [-0.4859547 ,  0.9757227 , -0.3315592 , ..., -0.41068095,\n",
       "          -0.01717883,  0.36384124],\n",
       "         ...,\n",
       "         [-0.20691094,  0.9684259 , -0.08245824, ..., -0.04241754,\n",
       "          -0.29768944, -0.12545791],\n",
       "         [-0.0321196 ,  0.83908284,  0.49803418, ..., -0.16062295,\n",
       "           0.29709876,  0.10070895],\n",
       "         [-0.4717    ,  0.4446189 , -0.492348  , ...,  0.01562437,\n",
       "          -0.55453414,  0.04149935]],\n",
       " \n",
       "        [[-0.57991517,  1.0401468 , -0.06598484, ..., -0.64004993,\n",
       "          -0.58237374,  0.7266147 ],\n",
       "         [-0.52608037,  0.60571074, -0.33460322, ..., -0.10379222,\n",
       "          -1.0356178 ,  0.27350858],\n",
       "         [-0.1121022 ,  1.0303864 , -0.0728159 , ..., -0.15667747,\n",
       "          -0.16051698, -0.14715838],\n",
       "         ...,\n",
       "         [-0.46303812,  0.4360067 , -0.49894214, ...,  0.02180409,\n",
       "          -0.55651677,  0.07156701],\n",
       "         [-0.46303812,  0.4360067 , -0.49894214, ...,  0.02180409,\n",
       "          -0.55651677,  0.07156701],\n",
       "         [-0.46303812,  0.4360067 , -0.49894214, ...,  0.02180409,\n",
       "          -0.55651677,  0.07156701]],\n",
       " \n",
       "        [[-0.09965828,  0.7317988 ,  0.14677355, ..., -0.5034324 ,\n",
       "          -0.2191711 , -0.47870666],\n",
       "         [-0.55820996,  0.6280488 , -0.3418926 , ..., -0.11689483,\n",
       "          -1.0354288 ,  0.2531646 ],\n",
       "         [-0.20411915,  1.2493924 ,  0.27541137, ..., -0.37676695,\n",
       "          -0.61524284,  0.1095133 ],\n",
       "         ...,\n",
       "         [-0.20172408,  0.99024117, -0.05939745, ..., -0.06720571,\n",
       "          -0.30963394, -0.12539259],\n",
       "         [-0.2041552 ,  0.8647083 , -0.28702375, ...,  0.20244277,\n",
       "          -0.3849128 ,  0.24573949],\n",
       "         [-0.1881428 ,  1.3028603 ,  0.01843738, ...,  0.05235198,\n",
       "          -0.22999646,  0.20840767]],\n",
       " \n",
       "        [[-0.3029388 ,  0.87868416,  0.11224037, ..., -0.14237635,\n",
       "          -0.2884258 ,  0.65225965],\n",
       "         [-0.528586  ,  0.6191629 , -0.32827362, ..., -0.10636336,\n",
       "          -1.055715  ,  0.25378054],\n",
       "         [ 0.0115146 ,  1.0011672 , -0.14351349, ..., -0.40340012,\n",
       "          -0.30102795, -0.5745939 ],\n",
       "         ...,\n",
       "         [-0.06429332,  1.2402841 ,  0.12542799, ...,  0.06369354,\n",
       "          -0.56079644,  0.37785724],\n",
       "         [-0.45084268,  0.44255024, -0.5064821 , ...,  0.0435601 ,\n",
       "          -0.5704252 ,  0.07000461],\n",
       "         [-0.45084268,  0.44255024, -0.5064821 , ...,  0.0435601 ,\n",
       "          -0.5704252 ,  0.07000461]],\n",
       " \n",
       "        [[-0.57597363,  0.91679174, -0.16516557, ...,  0.03413233,\n",
       "          -0.1715307 ,  0.07365479],\n",
       "         [-0.3106563 ,  1.0022182 , -0.7536593 , ..., -0.05684967,\n",
       "          -0.26292646,  0.3929745 ],\n",
       "         [-0.19054347,  1.2479237 ,  0.29243892, ..., -0.351181  ,\n",
       "          -0.61790097,  0.13472474],\n",
       "         ...,\n",
       "         [-0.44985706,  0.4397189 , -0.49211675, ...,  0.02044083,\n",
       "          -0.5607753 ,  0.07482801],\n",
       "         [-0.44985706,  0.4397189 , -0.49211675, ...,  0.02044083,\n",
       "          -0.5607753 ,  0.07482801],\n",
       "         [-0.44985723,  0.4397187 , -0.4921165 , ...,  0.02044109,\n",
       "          -0.5607753 ,  0.07482788]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[-0.32288408,  0.77380204,  0.09472945, ..., -0.08470309,\n",
       "          -0.30857486, -0.03168187],\n",
       "         [-0.5901527 ,  1.3777462 ,  0.02499796, ...,  0.51984894,\n",
       "          -0.21953927,  0.38398588],\n",
       "         [-0.22900927,  1.1622474 , -0.11301853, ...,  0.00190355,\n",
       "          -0.27013344, -0.0371573 ],\n",
       "         ...,\n",
       "         [-0.27534783,  1.055398  , -0.25484633, ..., -0.03193738,\n",
       "          -0.7763147 , -0.3028888 ],\n",
       "         [-0.22591037,  0.6843298 ,  0.48847586, ..., -0.13860042,\n",
       "           0.02069632, -0.20940633],\n",
       "         [-0.32509696,  0.33240724, -0.34506485, ...,  0.02974445,\n",
       "          -0.6500913 ,  0.35251355]],\n",
       " \n",
       "        [[-0.31534597,  0.91100216,  0.07907049, ..., -0.529747  ,\n",
       "          -0.5323754 ,  0.2453039 ],\n",
       "         [-0.3570455 ,  0.79164577, -0.17381723, ...,  0.10925429,\n",
       "          -0.8156294 , -0.2387103 ],\n",
       "         [-0.25401753,  0.7995841 ,  0.19826426, ...,  0.05604212,\n",
       "          -0.2685575 , -0.5294661 ],\n",
       "         ...,\n",
       "         [-0.3104289 ,  0.3278712 , -0.347443  , ...,  0.0202226 ,\n",
       "          -0.6499871 ,  0.38548452],\n",
       "         [-0.3104289 ,  0.3278712 , -0.347443  , ...,  0.0202226 ,\n",
       "          -0.6499871 ,  0.38548452],\n",
       "         [-0.3104289 ,  0.3278712 , -0.347443  , ...,  0.0202226 ,\n",
       "          -0.6499871 ,  0.38548452]],\n",
       " \n",
       "        [[-0.23389554,  0.7022018 ,  0.02850488, ..., -0.43022674,\n",
       "          -0.44304648, -0.857666  ],\n",
       "         [-0.38880837,  0.7988931 , -0.1843551 , ...,  0.11280034,\n",
       "          -0.80946004, -0.25356525],\n",
       "         [-0.08772203,  1.0685067 ,  0.29737765, ..., -0.27544245,\n",
       "          -0.6756042 ,  0.05353934],\n",
       "         ...,\n",
       "         [-0.25091076,  1.058633  , -0.22911575, ..., -0.06682339,\n",
       "          -0.8141154 , -0.30522498],\n",
       "         [-0.22604284,  0.6781508 , -0.17695905, ...,  0.2922937 ,\n",
       "          -0.47140685,  0.04219659],\n",
       "         [-0.14950162,  1.1017257 ,  0.17338108, ...,  0.21876356,\n",
       "          -0.41131365, -0.1874995 ]],\n",
       " \n",
       "        [[-0.33679512,  0.8799714 ,  0.10744777, ...,  0.27250573,\n",
       "          -0.18627855,  0.1575757 ],\n",
       "         [-0.37093896,  0.7970766 , -0.17596094, ...,  0.1058207 ,\n",
       "          -0.822822  , -0.25633734],\n",
       "         [ 0.03303695,  0.9441913 , -0.10310081, ..., -0.2959693 ,\n",
       "          -0.30297178, -0.98501205],\n",
       "         ...,\n",
       "         [ 0.0101068 ,  1.20435   ,  0.0668533 , ...,  0.15972295,\n",
       "          -0.51725507,  0.08398608],\n",
       "         [-0.29249153,  0.33392933, -0.35833713, ...,  0.0439032 ,\n",
       "          -0.6705172 ,  0.38622513],\n",
       "         [-0.29249153,  0.33392933, -0.35833713, ...,  0.0439032 ,\n",
       "          -0.6705172 ,  0.38622513]],\n",
       " \n",
       "        [[-0.7610193 ,  1.0344249 ,  0.01780337, ...,  0.10224497,\n",
       "          -0.11979387, -0.07301867],\n",
       "         [-0.03994232,  0.87097377, -0.5824915 , ..., -0.07343254,\n",
       "          -0.23751542,  0.05370812],\n",
       "         [-0.06220284,  1.0700524 ,  0.31304708, ..., -0.24617246,\n",
       "          -0.6587403 ,  0.06214108],\n",
       "         ...,\n",
       "         [-0.29064775,  0.3332142 , -0.33607143, ...,  0.03241941,\n",
       "          -0.6548718 ,  0.38378963],\n",
       "         [-0.29064775,  0.3332142 , -0.33607143, ...,  0.03241941,\n",
       "          -0.6548718 ,  0.38378963],\n",
       "         [-0.2906478 ,  0.3332144 , -0.33607152, ...,  0.03241955,\n",
       "          -0.65487164,  0.38378942]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[-2.74430513e-01,  5.11910498e-01,  4.03247774e-01, ...,\n",
       "           1.97507381e-01, -1.82315856e-01, -1.03919998e-01],\n",
       "         [-7.18495488e-01,  1.27830482e+00,  7.29189992e-01, ...,\n",
       "           4.65975493e-01, -1.08550042e-01, -5.10096252e-02],\n",
       "         [-1.31776720e-01,  8.91463995e-01,  9.85488594e-02, ...,\n",
       "           1.73944950e-01, -1.45635918e-01, -4.76566255e-02],\n",
       "         ...,\n",
       "         [-1.57777071e-01,  1.13873363e+00, -1.09833881e-01, ...,\n",
       "           2.99758315e-02, -7.01893330e-01, -5.48277497e-01],\n",
       "         [ 4.25018668e-02,  7.16163754e-01,  8.22536111e-01, ...,\n",
       "          -9.72468406e-02, -4.81252074e-02, -2.74655849e-01],\n",
       "         [-8.90795290e-02,  2.52496541e-01, -6.51866198e-04, ...,\n",
       "          -5.94878644e-02, -3.82872194e-01, -1.89790234e-01]],\n",
       " \n",
       "        [[-4.03413266e-01,  8.24754059e-01,  5.52297354e-01, ...,\n",
       "          -4.50448722e-01, -9.31306243e-01, -1.27493471e-01],\n",
       "         [-3.71337831e-01,  6.77712858e-01,  8.71186480e-02, ...,\n",
       "          -6.64058328e-02, -6.26704454e-01, -3.75460684e-01],\n",
       "         [-3.58702779e-01,  6.61786556e-01,  4.63579655e-01, ...,\n",
       "           6.06228262e-02, -8.46939310e-02, -9.89593327e-01],\n",
       "         ...,\n",
       "         [-8.53871107e-02,  2.61116922e-01,  1.01406723e-02, ...,\n",
       "          -7.09762350e-02, -3.94040465e-01, -1.84273720e-01],\n",
       "         [-8.53871107e-02,  2.61116922e-01,  1.01406723e-02, ...,\n",
       "          -7.09762350e-02, -3.94040465e-01, -1.84273720e-01],\n",
       "         [-8.53871107e-02,  2.61116922e-01,  1.01406723e-02, ...,\n",
       "          -7.09762350e-02, -3.94040465e-01, -1.84273720e-01]],\n",
       " \n",
       "        [[-2.53719658e-01,  5.16364336e-01,  2.32315987e-01, ...,\n",
       "          -4.05419588e-01, -4.19225931e-01, -7.40134656e-01],\n",
       "         [-3.77275527e-01,  6.74454093e-01,  6.99187964e-02, ...,\n",
       "          -5.86379021e-02, -6.04943693e-01, -3.69031549e-01],\n",
       "         [-6.46918416e-02,  9.87756610e-01,  3.94702733e-01, ...,\n",
       "          -2.48360798e-01, -3.95749450e-01, -3.82083744e-01],\n",
       "         ...,\n",
       "         [-1.44116834e-01,  1.17010188e+00, -9.81214494e-02, ...,\n",
       "          -2.43289471e-02, -7.35613286e-01, -5.37004530e-01],\n",
       "         [-2.48937696e-01,  7.50092924e-01,  9.55796242e-03, ...,\n",
       "           7.99615145e-01, -1.71513528e-01, -2.03253850e-02],\n",
       "         [-7.76562691e-02,  9.50871527e-01,  3.38425219e-01, ...,\n",
       "           1.20738715e-01, -4.16366547e-01, -4.41035390e-01]],\n",
       " \n",
       "        [[-2.68431753e-01,  9.50194776e-01,  4.58000153e-01, ...,\n",
       "           1.41253889e-01, -3.52864414e-02, -5.37388206e-01],\n",
       "         [-3.63575131e-01,  6.69380188e-01,  8.31410736e-02, ...,\n",
       "          -6.75178766e-02, -6.29509926e-01, -3.79180670e-01],\n",
       "         [ 2.83869922e-01,  6.78686142e-01,  3.35627735e-01, ...,\n",
       "          -1.50641054e-01, -5.13280869e-01, -9.42089200e-01],\n",
       "         ...,\n",
       "         [-1.09401755e-01,  1.14870095e+00,  6.08275712e-01, ...,\n",
       "           2.63572186e-02, -2.34794661e-01, -1.69004872e-01],\n",
       "         [-4.78756130e-02,  2.54295617e-01, -1.95429362e-02, ...,\n",
       "          -5.08070439e-02, -4.05560583e-01, -1.61636204e-01],\n",
       "         [-4.78756130e-02,  2.54295617e-01, -1.95429362e-02, ...,\n",
       "          -5.08070439e-02, -4.05560583e-01, -1.61636204e-01]],\n",
       " \n",
       "        [[-5.59570193e-01,  8.53401124e-01,  1.80050403e-01, ...,\n",
       "           1.29528776e-01,  1.25327110e-01, -4.23772216e-01],\n",
       "         [ 1.50835171e-01,  8.07354808e-01, -2.55367398e-01, ...,\n",
       "           4.25188392e-02, -6.60712868e-02, -2.17534631e-01],\n",
       "         [-4.05003130e-02,  9.90141511e-01,  3.99006367e-01, ...,\n",
       "          -2.44919509e-01, -4.01472807e-01, -3.80881876e-01],\n",
       "         ...,\n",
       "         [-5.65172434e-02,  2.56750107e-01, -5.89092448e-03, ...,\n",
       "          -6.55096322e-02, -3.95044148e-01, -1.61578447e-01],\n",
       "         [-5.65172434e-02,  2.56750107e-01, -5.89092448e-03, ...,\n",
       "          -6.55096322e-02, -3.95044148e-01, -1.61578447e-01],\n",
       "         [-5.65173924e-02,  2.56749809e-01, -5.89079037e-03, ...,\n",
       "          -6.55095354e-02, -3.95043939e-01, -1.61578387e-01]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[ 1.64016366e-01,  3.38046908e-01,  3.90285492e-01, ...,\n",
       "           1.77713528e-01, -8.45133960e-01, -3.85767877e-01],\n",
       "         [-2.25499883e-01,  1.11980033e+00,  8.43870044e-01, ...,\n",
       "           4.32758510e-01, -5.90047836e-01, -6.54526472e-01],\n",
       "         [ 3.13574165e-01,  9.41230893e-01,  7.49631226e-02, ...,\n",
       "          -1.16637319e-01, -5.66306174e-01, -1.25172660e-01],\n",
       "         ...,\n",
       "         [ 4.10738409e-01,  9.98431444e-01, -9.44455862e-02, ...,\n",
       "           1.01885468e-01, -9.34290588e-01, -6.68509603e-01],\n",
       "         [ 3.61144185e-01,  5.34030914e-01,  6.71991587e-01, ...,\n",
       "          -7.92584419e-02, -3.41131985e-01, -3.02548021e-01],\n",
       "         [ 1.36140376e-01,  1.77256897e-01, -1.52073801e-04, ...,\n",
       "           2.59832025e-01, -6.85088158e-01,  9.21514034e-02]],\n",
       " \n",
       "        [[ 8.19584727e-02,  5.09656429e-01,  4.46740717e-01, ...,\n",
       "          -4.05333430e-01, -1.00891685e+00, -5.36407590e-01],\n",
       "         [ 1.45295769e-01,  5.25890112e-01,  1.74723029e-01, ...,\n",
       "           1.24052837e-01, -7.55685985e-01, -7.00780392e-01],\n",
       "         [-8.56383145e-02,  6.48364365e-01,  5.48557460e-01, ...,\n",
       "          -8.36189836e-02, -7.21005440e-01, -1.21300673e+00],\n",
       "         ...,\n",
       "         [ 1.48946360e-01,  1.74295753e-01,  1.45566240e-02, ...,\n",
       "           2.43664175e-01, -7.03383684e-01,  1.04405664e-01],\n",
       "         [ 1.48946360e-01,  1.74295753e-01,  1.45566240e-02, ...,\n",
       "           2.43664175e-01, -7.03383684e-01,  1.04405664e-01],\n",
       "         [ 1.48946360e-01,  1.74295753e-01,  1.45566240e-02, ...,\n",
       "           2.43664175e-01, -7.03383684e-01,  1.04405664e-01]],\n",
       " \n",
       "        [[ 2.59648025e-01,  5.55644691e-01,  1.10544994e-01, ...,\n",
       "          -4.04387355e-01, -4.72335428e-01, -9.85881686e-01],\n",
       "         [ 1.30385637e-01,  5.41886687e-01,  1.45624772e-01, ...,\n",
       "           1.26377642e-01, -7.62334585e-01, -6.84542358e-01],\n",
       "         [ 2.50791728e-01,  9.96247828e-01,  3.07862669e-01, ...,\n",
       "          -1.16912007e-01, -9.25107062e-01, -6.34424746e-01],\n",
       "         ...,\n",
       "         [ 4.29737866e-01,  1.03640652e+00, -7.71206468e-02, ...,\n",
       "           4.32642847e-02, -9.78289962e-01, -6.55290961e-01],\n",
       "         [ 6.15912080e-02,  7.56051302e-01,  2.71442473e-01, ...,\n",
       "           8.88273716e-01, -6.13817930e-01, -1.22023061e-01],\n",
       "         [ 3.40926528e-01,  8.15393269e-01,  2.13336200e-02, ...,\n",
       "          -9.41680074e-02, -6.58961296e-01, -7.77950644e-01]],\n",
       " \n",
       "        [[ 3.49187851e-01,  1.01770544e+00,  5.41860402e-01, ...,\n",
       "           7.81598687e-02, -5.56616783e-01, -6.99546218e-01],\n",
       "         [ 1.50693476e-01,  5.15094817e-01,  1.63437173e-01, ...,\n",
       "           1.32982746e-01, -7.45988250e-01, -6.90414548e-01],\n",
       "         [ 6.59062386e-01,  7.62276173e-01,  3.75419348e-01, ...,\n",
       "          -1.82753205e-01, -9.52601314e-01, -1.15487909e+00],\n",
       "         ...,\n",
       "         [ 4.47939038e-01,  1.27579582e+00,  4.35561657e-01, ...,\n",
       "           1.37551948e-01, -4.77965236e-01, -5.40123224e-01],\n",
       "         [ 1.77579418e-01,  1.61175758e-01, -1.01859868e-03, ...,\n",
       "           2.77008772e-01, -7.05082417e-01,  1.05233960e-01],\n",
       "         [ 1.77579418e-01,  1.61175758e-01, -1.01859868e-03, ...,\n",
       "           2.77008772e-01, -7.05082417e-01,  1.05233960e-01]],\n",
       " \n",
       "        [[-9.98882055e-02,  8.79337847e-01, -1.19350076e-01, ...,\n",
       "           4.14246917e-02, -4.21622634e-01, -6.40697598e-01],\n",
       "         [ 8.06506276e-01,  4.69970047e-01, -3.76133621e-02, ...,\n",
       "           2.57113814e-01, -2.21814170e-01, -6.04557633e-01],\n",
       "         [ 2.75047898e-01,  9.79577243e-01,  3.16849560e-01, ...,\n",
       "          -8.70923847e-02, -9.12405610e-01, -6.32594705e-01],\n",
       "         ...,\n",
       "         [ 1.77544177e-01,  1.63755789e-01, -7.62693584e-03, ...,\n",
       "           2.72293419e-01, -7.00077534e-01,  1.23497263e-01],\n",
       "         [ 1.77544177e-01,  1.63755789e-01, -7.62693584e-03, ...,\n",
       "           2.72293419e-01, -7.00077534e-01,  1.23497263e-01],\n",
       "         [ 1.77544147e-01,  1.63755700e-01, -7.62672722e-03, ...,\n",
       "           2.72293389e-01, -7.00077057e-01,  1.23497702e-01]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[ 0.19224516,  0.15725133,  0.4361377 , ...,  0.09676585,\n",
       "          -0.94629574, -0.09486723],\n",
       "         [ 0.22104543,  1.0367383 ,  0.71853703, ...,  0.14348271,\n",
       "          -0.49900782, -0.3669126 ],\n",
       "         [ 0.31674254,  0.6806577 , -0.13397536, ..., -0.17302887,\n",
       "          -0.5364847 ,  0.21908715],\n",
       "         ...,\n",
       "         [ 0.547841  ,  0.7655637 , -0.03672777, ...,  0.19844842,\n",
       "          -0.7993056 , -0.2178312 ],\n",
       "         [ 0.78675324,  0.38047737,  0.6079746 , ..., -0.16646814,\n",
       "          -0.52189434,  0.09114535],\n",
       "         [ 0.18363026,  0.3537106 ,  0.04356887, ...,  0.43760931,\n",
       "          -0.59036434,  0.29600418]],\n",
       " \n",
       "        [[ 0.22440994,  0.45738262,  0.40588528, ..., -0.24127957,\n",
       "          -0.7495285 , -0.16684984],\n",
       "         [ 0.38822466,  0.5239353 ,  0.00211012, ...,  0.08924396,\n",
       "          -0.65055203, -0.46886483],\n",
       "         [ 0.260095  ,  0.3942051 ,  0.38765532, ..., -0.2417522 ,\n",
       "          -0.3575812 , -0.91135347],\n",
       "         ...,\n",
       "         [ 0.19346952,  0.3382807 ,  0.05493277, ...,  0.43200737,\n",
       "          -0.59978795,  0.29399186],\n",
       "         [ 0.19346952,  0.3382807 ,  0.05493277, ...,  0.43200737,\n",
       "          -0.59978795,  0.29399186],\n",
       "         [ 0.19346952,  0.3382807 ,  0.05493277, ...,  0.43200737,\n",
       "          -0.59978795,  0.29399186]],\n",
       " \n",
       "        [[ 0.42271292,  0.2821549 ,  0.04404822, ..., -0.36614028,\n",
       "          -0.5197748 , -0.8956431 ],\n",
       "         [ 0.38262075,  0.5410224 , -0.01069322, ...,  0.0958166 ,\n",
       "          -0.6634073 , -0.44747096],\n",
       "         [ 0.31280074,  0.8325119 ,  0.16930617, ..., -0.15098587,\n",
       "          -0.8776697 , -0.23869522],\n",
       "         ...,\n",
       "         [ 0.5639881 ,  0.8004873 , -0.01534036, ...,  0.15868399,\n",
       "          -0.8322686 , -0.21550159],\n",
       "         [ 0.48047373,  0.3519264 ,  0.08304013, ...,  0.89629126,\n",
       "          -0.5371802 ,  0.01168792],\n",
       "         [ 0.34269112,  0.71189344, -0.0046331 , ...,  0.09159774,\n",
       "          -0.680427  , -0.56726384]],\n",
       " \n",
       "        [[ 0.7086614 ,  0.8324303 ,  0.36543274, ...,  0.02262393,\n",
       "          -0.5778059 , -0.01069731],\n",
       "         [ 0.39634037,  0.5123774 , -0.00818952, ...,  0.08981749,\n",
       "          -0.63747096, -0.4438383 ],\n",
       "         [ 0.714411  ,  0.7355272 ,  0.09288343, ..., -0.11519805,\n",
       "          -0.63429195, -0.59059244],\n",
       "         ...,\n",
       "         [ 0.6968347 ,  1.0135891 ,  0.07524435, ..., -0.2086043 ,\n",
       "          -0.37838048, -0.18499266],\n",
       "         [ 0.22817421,  0.3360591 ,  0.05436578, ...,  0.44358075,\n",
       "          -0.5911072 ,  0.31669766],\n",
       "         [ 0.22817421,  0.3360591 ,  0.05436578, ...,  0.44358075,\n",
       "          -0.5911072 ,  0.31669766]],\n",
       " \n",
       "        [[ 0.07877538,  0.64742357, -0.2779122 , ...,  0.02439202,\n",
       "          -0.41030654, -0.40189898],\n",
       "         [ 0.8949383 ,  0.541625  , -0.2551278 , ...,  0.17193942,\n",
       "          -0.35245138, -0.0898173 ],\n",
       "         [ 0.32213128,  0.80810577,  0.17967567, ..., -0.14864953,\n",
       "          -0.8813778 , -0.23654643],\n",
       "         ...,\n",
       "         [ 0.20904058,  0.3330243 ,  0.04413987, ...,  0.43780655,\n",
       "          -0.6017957 ,  0.31126094],\n",
       "         [ 0.20904058,  0.3330243 ,  0.04413987, ...,  0.43780655,\n",
       "          -0.6017957 ,  0.31126094],\n",
       "         [ 0.20904067,  0.33302465,  0.04413966, ...,  0.43780667,\n",
       "          -0.6017953 ,  0.31126124]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 17, 28996), dtype=float32, numpy=\n",
       " array([[[ 0.04578462,  0.04263703,  0.35006744, ..., -0.04909407,\n",
       "          -0.62672454, -0.52413213],\n",
       "         [-0.12671943,  0.67552364,  0.5051607 , ..., -0.12348177,\n",
       "          -0.2739885 , -0.7724408 ],\n",
       "         [ 0.09513143,  0.480335  ,  0.09630401, ..., -0.4880525 ,\n",
       "          -0.20890477, -0.05855425],\n",
       "         ...,\n",
       "         [ 0.14539438,  0.51112974,  0.05497143, ..., -0.01889101,\n",
       "          -0.47215956, -0.47424823],\n",
       "         [ 0.4810764 ,  0.16985002,  0.518323  , ..., -0.28426397,\n",
       "          -0.4056816 , -0.37623346],\n",
       "         [ 0.10000828,  0.392194  , -0.1892504 , ...,  0.2836862 ,\n",
       "          -0.67562586,  0.02361705]],\n",
       " \n",
       "        [[ 0.00887576,  0.19809745,  0.46250582, ..., -0.45949474,\n",
       "          -0.5991149 , -0.41900772],\n",
       "         [ 0.00209871,  0.26816154,  0.15982099, ..., -0.0522234 ,\n",
       "          -0.561666  , -0.8108075 ],\n",
       "         [ 0.12960157,  0.1470581 ,  0.52923226, ..., -0.14861152,\n",
       "           0.11357806, -1.2568088 ],\n",
       "         ...,\n",
       "         [ 0.10559464,  0.3791371 , -0.16500609, ...,  0.2810328 ,\n",
       "          -0.6785735 ,  0.03328335],\n",
       "         [ 0.10559464,  0.3791371 , -0.16500609, ...,  0.2810328 ,\n",
       "          -0.6785735 ,  0.03328335],\n",
       "         [ 0.10559464,  0.3791371 , -0.16500609, ...,  0.2810328 ,\n",
       "          -0.6785735 ,  0.03328335]],\n",
       " \n",
       "        [[ 0.17285845,  0.14233495,  0.05415368, ..., -0.46449888,\n",
       "          -0.14219825, -1.2501783 ],\n",
       "         [-0.01854262,  0.2748685 ,  0.16501352, ..., -0.04236048,\n",
       "          -0.57541496, -0.7867858 ],\n",
       "         [ 0.18252224,  0.5021683 ,  0.3608102 , ..., -0.35120004,\n",
       "          -0.7544833 , -0.44697505],\n",
       "         ...,\n",
       "         [ 0.14694722,  0.53825057,  0.06076968, ..., -0.06257436,\n",
       "          -0.5177295 , -0.45474565],\n",
       "         [ 0.12240075,  0.29977363,  0.27256328, ...,  0.737312  ,\n",
       "          -0.24919748, -0.542535  ],\n",
       "         [ 0.11457108,  0.20749167, -0.11921066, ...,  0.07430112,\n",
       "          -0.5518844 , -0.7890179 ]],\n",
       " \n",
       "        [[ 0.28618824,  0.40541774,  0.24502826, ..., -0.01483542,\n",
       "          -0.23578978, -0.5555054 ],\n",
       "         [-0.00530213,  0.26645425,  0.15626681, ..., -0.05250934,\n",
       "          -0.55415857, -0.7953366 ],\n",
       "         [ 0.6263547 ,  0.35217065,  0.2040407 , ..., -0.35154074,\n",
       "          -0.2403318 , -0.9928783 ],\n",
       "         ...,\n",
       "         [ 0.4793702 ,  0.40251136,  0.12126018, ..., -0.31531566,\n",
       "          -0.13144764, -0.50488794],\n",
       "         [ 0.14408176,  0.34869352, -0.17242286, ...,  0.2875553 ,\n",
       "          -0.6876906 ,  0.03997435],\n",
       "         [ 0.14408176,  0.34869352, -0.17242286, ...,  0.2875553 ,\n",
       "          -0.6876906 ,  0.03997435]],\n",
       " \n",
       "        [[-0.01518518,  0.2708584 , -0.16380306, ..., -0.18339555,\n",
       "          -0.24877203, -0.50396335],\n",
       "         [ 0.53448796,  0.16158903, -0.03078744, ...,  0.08231831,\n",
       "          -0.3264437 , -0.41128403],\n",
       "         [ 0.19319005,  0.49420103,  0.3550819 , ..., -0.34236568,\n",
       "          -0.7677072 , -0.4589869 ],\n",
       "         ...,\n",
       "         [ 0.11316237,  0.3663373 , -0.1746746 , ...,  0.28975296,\n",
       "          -0.6968244 ,  0.03880382],\n",
       "         [ 0.11316237,  0.3663373 , -0.1746746 , ...,  0.28975296,\n",
       "          -0.6968244 ,  0.03880382],\n",
       "         [ 0.11316213,  0.36633742, -0.17467467, ...,  0.28975287,\n",
       "          -0.6968243 ,  0.03880364]]], dtype=float32)>]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs['all_layer_token_logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "6bb25aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true_dict, y_pred_dict):\n",
    "    \n",
    "    loss_dict = {}\n",
    "    loss_holder = []\n",
    "    for i, layer_output in enumerate(y_pred_dict['all_layer_token_logits']):\n",
    "        layer_loss = cross_entropy_loss(labels=y_true_dict['masked_lm_labels'], \n",
    "                                       logits=layer_output, \n",
    "                                       label_weights=y_true_dict['masked_lm_mask'])\n",
    "        loss_dict['layer_{}'.format(i)] = layer_loss\n",
    "        loss_holder.append(layer_loss)\n",
    "    loss_dict['loss'] = tf.reduce_mean(loss_holder)\n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "1daf4214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_0': <tf.Tensor: shape=(), dtype=float32, numpy=10.438091>,\n",
       " 'layer_1': <tf.Tensor: shape=(), dtype=float32, numpy=10.436256>,\n",
       " 'layer_2': <tf.Tensor: shape=(), dtype=float32, numpy=10.396082>,\n",
       " 'layer_3': <tf.Tensor: shape=(), dtype=float32, numpy=10.433259>,\n",
       " 'layer_4': <tf.Tensor: shape=(), dtype=float32, numpy=10.42015>,\n",
       " 'layer_5': <tf.Tensor: shape=(), dtype=float32, numpy=10.434258>,\n",
       " 'layer_6': <tf.Tensor: shape=(), dtype=float32, numpy=10.450171>,\n",
       " 'layer_7': <tf.Tensor: shape=(), dtype=float32, numpy=10.464069>,\n",
       " 'layer_8': <tf.Tensor: shape=(), dtype=float32, numpy=10.49289>,\n",
       " 'layer_9': <tf.Tensor: shape=(), dtype=float32, numpy=10.50401>,\n",
       " 'layer_10': <tf.Tensor: shape=(), dtype=float32, numpy=10.475094>,\n",
       " 'layer_11': <tf.Tensor: shape=(), dtype=float32, numpy=10.440686>,\n",
       " 'loss': <tf.Tensor: shape=(), dtype=float32, numpy=10.448751>}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(batch_labels, model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedTextGenerator(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, tokenizer, top_k=5):\n",
    "        self.tokenizer = tokenizer\n",
    "        model , config = BertModel.get_model(model_name='bert-base-cased',\n",
    "                                    use_masked_lm_positions=False, \n",
    "                                    return_all_layer_outputs=True)\n",
    "        self.original_model = model\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.original_model.set_weights(self.model.get_weights())\n",
    "        sample_text = \"I have watched this [MASK] and it was awesome\"\n",
    "\n",
    "        input_ids = tf.constant(self.tokenizer.encode(sample_text))\n",
    "\n",
    "        masked_index = np.where(input_ids == MASK_ID)[0][0]\n",
    "        input_ids = tf.expand_dims(input_ids, axis=0)\n",
    "        input_type_ids = tf.zeros_like(input_ids)\n",
    "        input_mask     = tf.ones_like(input_ids)\n",
    "        inputs = {}\n",
    "        inputs[\"input_ids\"] = input_ids\n",
    "        inputs[\"input_type_ids\"] = input_type_ids\n",
    "        inputs[\"input_mask\"] = input_mask\n",
    "        outputs = self.original_model(inputs)\n",
    "\n",
    "        for i, layer_output in enumerate(outputs['all_layer_token_logits']):\n",
    "          prob_value = tf.reduce_max(layer_output, axis=-1)[0][masked_index]\n",
    "          predicted_token = self.tokenizer.decode([tf.argmax(layer_output, axis=-1)[0][masked_index]])\n",
    "          print(\"Layer {}, {}, {}\".format(i, predicted_token, prob_value))\n",
    "\n",
    "\n",
    "generator_callback = MaskedTextGenerator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c046b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
