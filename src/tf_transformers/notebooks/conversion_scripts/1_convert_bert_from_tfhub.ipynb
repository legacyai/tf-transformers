{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook shows how to convert a BERT model to tf_transformers framework\n",
    "# We will model from BERT hub (downloaded locally) and convert it into\n",
    "# tf_transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hub model\n",
    "import tensorflow_hub as hub\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tf_transformers.models import BERTEncoder\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0-rc0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_hub = hub.KerasLayer(\"../../../pretrained_models/bert_uncased/\",\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_hub.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_probs_dropout_prob': 0.1,\n",
       " 'hidden_act': 'gelu',\n",
       " 'intermediate_act': 'gelu',\n",
       " 'hidden_dropout_prob': 0.1,\n",
       " 'embedding_size': 768,\n",
       " 'initializer_range': 0.02,\n",
       " 'intermediate_size': 3072,\n",
       " 'max_position_embeddings': 512,\n",
       " 'num_attention_heads': 12,\n",
       " 'num_hidden_layers': 12,\n",
       " 'type_vocab_size': 2,\n",
       " 'vocab_size': 30522,\n",
       " 'layer_norm_epsilon': 1e-12}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config  = json.load(open(\"../model_directory/bert_base/bert_config.json\"))\n",
    "# config['max_position_embeddings'] = 1024\n",
    "# config['intermediate_size'] = 4096\n",
    "# config['num_attention_heads'] = 16\n",
    "# config['num_hidden_layers'] = 24\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16 * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:input_type_ids ---> Tensor(\"input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:Initialized Variables\n"
     ]
    }
   ],
   "source": [
    "# Load Hub Model\n",
    "# To download Hub Model\n",
    "# https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\n",
    "# Download and unzip\n",
    "\n",
    "bert_hub = hub.KerasLayer(\"../../../pretrained_models/bert_uncased/\",\n",
    "                            trainable=True)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.keras.backend.clear_session()\n",
    "config  = json.load(open(\"../model_directory/bert_base/bert_config.json\"))\n",
    "# We have Keras/Legacy Layer here (Not keras.model)\n",
    "model_layer = BERTEncoder(config=config,\n",
    "                  name='bert',\n",
    "                  mask_mode='user_defined',\n",
    "                  is_training=False\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt         = tf.train.load_checkpoint(\"/Users/PRVATE/pretrained_models/bert_base/bert_model.ckpt\")\n",
    "model_vars   = tf.train.list_variables(\"/Users/PRVATE/pretrained_models/bert_base/bert_model.ckpt\")\n",
    "len(model_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_probs_dropout_prob': 0.1,\n",
       " 'hidden_act': 'gelu',\n",
       " 'intermediate_act': 'gelu',\n",
       " 'hidden_dropout_prob': 0.1,\n",
       " 'embedding_size': 768,\n",
       " 'initializer_range': 0.02,\n",
       " 'intermediate_size': 3072,\n",
       " 'max_position_embeddings': 512,\n",
       " 'num_attention_heads': 12,\n",
       " 'num_hidden_layers': 12,\n",
       " 'type_vocab_size': 2,\n",
       " 'vocab_size': 30522,\n",
       " 'layer_norm_epsilon': 1e-12}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Done assigning variables weights\n"
     ]
    }
   ],
   "source": [
    "# BERT hub variables to BERT model\n",
    "mapping_dict = {\n",
    "    'bert_model/word_embeddings/embeddings:0': 'tf_transformers/bert/word_embeddings/embeddings:0',\n",
    "    'bert_model/embedding_postprocessor/type_embeddings:0': 'tf_transformers/bert/type_embeddings/embeddings:0',\n",
    "    'bert_model/embedding_postprocessor/position_embeddings:0': 'tf_transformers/bert/positional_embeddings/embeddings:0',\n",
    "    'bert_model/embedding_postprocessor/layer_norm/gamma:0': 'tf_transformers/bert/embeddings/layer_norm/gamma:0',\n",
    "    'bert_model/embedding_postprocessor/layer_norm/beta:0': 'tf_transformers/bert/embeddings/layer_norm/beta:0',\n",
    "    'bert_model/pooler_transform/kernel:0': 'tf_transformers/bert/pooler_transform/kernel:0',\n",
    "    'bert_model/pooler_transform/bias:0': 'tf_transformers/bert/pooler_transform/bias:0'\n",
    "}\n",
    "\n",
    "tf_transformers_bert_index_dict = {}\n",
    "for index, var in enumerate(model_layer.variables):\n",
    "    # print(index, var.name, var.shape)\n",
    "    temp_var = var.name.replace('tf_transformers/bert/transformer/', '')\n",
    "    tf_transformers_bert_index_dict[temp_var] = index\n",
    "    \n",
    "# legacy_ai <-- hub\n",
    "assigned_map = []\n",
    "assigned_map_values = []\n",
    "for var in bert_hub.variables:\n",
    "    \n",
    "    if 'Variable:0' in var.name:\n",
    "        continue\n",
    "    \n",
    "    temp_var = var.name.replace('bert_model/encoder/', '')\n",
    "    \n",
    "    # If var in mapping dict, then we can get tf_transformers_bert_index_dict[mapping_dict[var]] index\n",
    "    if temp_var in mapping_dict:\n",
    "        index = tf_transformers_bert_index_dict[mapping_dict[temp_var]]\n",
    "        model_layer.variables[index].assign(var)\n",
    "        assigned_map.append((var.name, model_layer.variables[index].name))\n",
    "        assigned_map_values.append((tf.reduce_sum(var).numpy(), tf.reduce_sum(model_layer.variables[index]).numpy()))\n",
    "        continue\n",
    "        \n",
    "    # If not in mapping_dict, then mostly it is from attention layer\n",
    "    index = tf_transformers_bert_index_dict[temp_var]\n",
    "    if 'query/kernel:0' in temp_var or 'key/kernel:0' in temp_var or 'value/kernel:0' in temp_var:\n",
    "        # hub (2D) to tf_transformers (3D)\n",
    "        model_layer.variables[index].assign(tf.reshape(var, (config['embedding_size'],\n",
    "                                                            config['num_attention_heads'], \n",
    "                                                            config['embedding_size'] // config['num_attention_heads'])))\n",
    "        \n",
    "        assigned_map.append((var.name, model_layer.variables[index].name))\n",
    "        assigned_map_values.append((tf.reduce_sum(var).numpy(), tf.reduce_sum(model_layer.variables[index]).numpy()))\n",
    "        continue\n",
    "\n",
    "    if 'query/bias:0' in temp_var or 'key/bias:0' in temp_var or 'value/bias:0' in temp_var:\n",
    "        # hub (2D) to tf_transformers (3D)\n",
    "        model_layer.variables[index].assign(tf.reshape(var, (config['num_attention_heads'],\n",
    "                                                            config['embedding_size'] // config['num_attention_heads'])))\n",
    "        assigned_map.append((var.name, model_layer.variables[index].name))\n",
    "        assigned_map_values.append((tf.reduce_sum(var).numpy(), tf.reduce_sum(model_layer.variables[index]).numpy()))\n",
    "        continue\n",
    "        \n",
    "    # Rest of the variables\n",
    "    model_layer.variables[index].assign(var)\n",
    "    assigned_map.append((var.name, model_layer.variables[index].name))\n",
    "    assigned_map_values.append((tf.reduce_sum(var).numpy(), tf.reduce_sum(model_layer.variables[index]).numpy()))\n",
    "\n",
    "    \n",
    "logging.info(\"Done assigning variables weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_output --> tf.Tensor(-2.06532, shape=(), dtype=float32) --> (1, 768)\n",
    "token_embeddings --> tf.Tensor(-26.426851, shape=(), dtype=float32) --> (1, 3, 768)\n",
    "token_logits --> tf.Tensor(-17970.629, shape=(), dtype=float32) --> (1, 3, 30522)\n",
    "last_token_logits --> tf.Tensor(-4169.4917, shape=(), dtype=float32) --> (1, 30522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results from Hub and tf_transformers\n",
    "\n",
    "results_hub      = bert_hub([tf.constant([[1, 2,3]]), tf.constant([[1, 1,1]]), tf.constant([[0,0,0]])])\n",
    "results_legacy   = model_layer({'input_ids': tf.constant([[1, 2,3]]), \n",
    "                                'input_mask': tf.constant([[1,1,1]]), \n",
    "                                'input_type_ids': tf.constant([[0, 0, 0]])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-2.0653088, shape=(), dtype=float32) --> (1, 768)\n",
      "tf.Tensor(-26.426857, shape=(), dtype=float32) --> (1, 3, 768)\n"
     ]
    }
   ],
   "source": [
    "for r in results_hub:\n",
    "    print(tf.reduce_sum(r), '-->', r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-10.324542, shape=(), dtype=float32) --> (2, 768)\n",
      "tf.Tensor(-99.82985, shape=(), dtype=float32) --> (2, 5, 768)\n"
     ]
    }
   ],
   "source": [
    "input_ids = tf.constant([[1, 9, 10, 11, 23], \n",
    "                         [1, 22, 234, 432, 2349]])\n",
    "input_mask = tf.ones_like(input_ids)\n",
    "input_type_ids = tf.ones_like(input_ids)\n",
    "results_hub      = bert_hub([input_ids, input_mask, input_type_ids])\n",
    "for r in results_hub:\n",
    "    print(tf.reduce_sum(r), '-->', r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_output --> tf.Tensor(-2.0653143, shape=(), dtype=float32) --> (1, 768)\n",
      "token_embeddings --> tf.Tensor(-26.426872, shape=(), dtype=float32) --> (1, 3, 768)\n",
      "token_logits --> tf.Tensor(-17970.516, shape=(), dtype=float32) --> (1, 3, 30522)\n",
      "last_token_logits --> tf.Tensor(-4169.453, shape=(), dtype=float32) --> (1, 30522)\n"
     ]
    }
   ],
   "source": [
    "for k, r in results_legacy.items():\n",
    "    if isinstance(r, list):\n",
    "        continue\n",
    "    print(k, '-->', tf.reduce_sum(r), '-->', r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "checkpoint_dir = '../model_directory/bert_base'\n",
    "ckpt    = tf.train.Checkpoint(model=model_layer)\n",
    "manager = tf.train.CheckpointManager(ckpt, checkpoint_dir, max_to_keep=1)\n",
    "save_path = manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_output --> tf.Tensor(-10.324546, shape=(), dtype=float32) --> (2, 768)\n",
      "token_embeddings --> tf.Tensor(-99.82982, shape=(), dtype=float32) --> (2, 5, 768)\n",
      "token_logits --> tf.Tensor(-4488.868, shape=(), dtype=float32) --> (2, 5, 30522)\n",
      "last_token_logits --> tf.Tensor(199.83713, shape=(), dtype=float32) --> (2, 30522)\n"
     ]
    }
   ],
   "source": [
    "input_ids = tf.constant([[1, 9, 10, 11, 23], \n",
    "                         [1, 22, 234, 432, 2349]])\n",
    "input_mask = tf.ones_like(input_ids)\n",
    "input_type_ids = tf.ones_like(input_ids)\n",
    "\n",
    "results_legacy = model_layer({'input_ids': input_ids, \n",
    "                                'input_mask': input_mask, \n",
    "                                'input_type_ids': input_type_ids})\n",
    "\n",
    "\n",
    "for k, r in results_legacy.items():\n",
    "    if isinstance(r, list):\n",
    "        continue\n",
    "    print(k, '-->', tf.reduce_sum(r), '-->', r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
