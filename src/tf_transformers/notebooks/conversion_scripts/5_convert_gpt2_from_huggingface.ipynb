{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/PRVATE/Documents/tf_transformers/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFGPT2Model\n",
    "from tf_transformers.models import GPT2Encoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "from tf_transformers.utils import convert_gpt2_hf_to_tf_transformers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at /Users/PRVATE/HUggingFace_Models/gpt2/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load HF model\n",
    "\n",
    "# Always do this\n",
    "\n",
    "\n",
    "model_hf_location = '/Users/PRVATE/HUggingFace_Models/gpt2/'\n",
    "model_hf = TFGPT2Model.from_pretrained(model_hf_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training`                     to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:input_ids ---> Tensor(\"input_ids_1:0\", shape=(None, None), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Load tf_transformers model\n",
    "# Most config we will be providing\n",
    "\n",
    "# Default configs for the model\n",
    "# Default configs for the model\n",
    "model_config_dir = '/Users/PRVATE/Documents/tf_transformers/model_configs/'\n",
    "model_name = 'gpt2_base'\n",
    "config_location = os.path.join(model_config_dir, model_name, 'config.json')\n",
    "config = json.load(open(config_location))\n",
    "# Always do this\n",
    "\n",
    "\n",
    "# tf_transformers Layer (an extension of Keras Layer)\n",
    "# This is not Keras model, but extension of keras Layer\n",
    "\n",
    "model_layer = GPT2Encoder(config=config,\n",
    "                      name='gpt2',\n",
    "                      mask_mode=config['mask_mode'],\n",
    "                      is_training=False, \n",
    "                      use_dropout=False,\n",
    "                      )\n",
    "# model_dir = None, because we have not initialized the model with proper variable values\n",
    "model_tf_transformers = model_layer.get_and_load_model(model_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Deleteing huggingface model for saving memory\n",
      "INFO:absl:Done assigning variables weights . Total 100\n"
     ]
    }
   ],
   "source": [
    "convert_gpt2_hf_to_tf_transformers(model_hf, model_tf_transformers, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embeddings --> tf.Tensor(2371.2754, shape=(), dtype=float32) --> (2, 5, 768)\n",
      "token_logits --> tf.Tensor(-34781264.0, shape=(), dtype=float32) --> (2, 5, 50257)\n",
      "last_token_logits --> tf.Tensor(-8346981.0, shape=(), dtype=float32) --> (2, 50257)\n"
     ]
    }
   ],
   "source": [
    "# Please have a look at tf_transformers/extra/*.py for reference values\n",
    "\n",
    "input_ids  = tf.constant([[1, 9, 10, 11, 23], \n",
    "                         [1, 22, 234, 432, 2349]])\n",
    "\n",
    "input_mask = tf.ones_like(input_ids)\n",
    "input_type_ids = tf.zeros_like(input_ids)\n",
    "\n",
    "inputs = {'input_ids': input_ids, \n",
    "}\n",
    "\n",
    "results_tf_transformers   = model_tf_transformers(inputs)\n",
    "for k, r in results_tf_transformers.items():\n",
    "    if isinstance(r, list):\n",
    "        continue\n",
    "    print(k, '-->', tf.reduce_sum(r), '-->', r.shape)\n",
    "    \n",
    "    \n",
    "# For GPT2 Base \n",
    "\n",
    "# token_embeddings --> tf.Tensor(2371.2751, shape=(), dtype=float32) --> (2, 5, 768)\n",
    "# token_logits --> tf.Tensor(-34781260.0, shape=(), dtype=float32) --> (2, 5, 50257)\n",
    "# last_token_logits --> tf.Tensor(-8346980.5, shape=(), dtype=float32) --> (2, 50257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2370.4778, shape=(), dtype=float32) --> (2, 5, 768)\n"
     ]
    }
   ],
   "source": [
    "# Huggingface Model\n",
    "input_ids  = tf.constant([[1, 9, 10, 11, 23], \n",
    "                         [1, 22, 234, 432, 2349]])\n",
    "\n",
    "results_hf = model_hf([input_ids])\n",
    "for k in results_hf:\n",
    "    if isinstance(k, tf.Tensor):\n",
    "        print(tf.reduce_sum(k), '-->', k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at /Users/PRVATE/tf_transformers_models/gpt2/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "model_loc  = '/Users/PRVATE/tf_transformers_models/'\n",
    "checkpoint_dir = os.path.join(model_loc, model_name)\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    raise FileExistsError()\n",
    "\n",
    "# If you want to save the model as checkpoints\n",
    "checkpoint = tf.train.Checkpoint(model=model_tf_transformers)\n",
    "manager = tf.train.CheckpointManager(\n",
    "    checkpoint, directory=checkpoint_dir, max_to_keep=1\n",
    ")\n",
    "manager.save()\n",
    "print(\"Saved at {}\".format(manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
