{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFT5Model, T5Tokenizer\n",
    "from tf_transformers.models import T5Model\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tf_transformers.utils import convert_t5_hf_to_tf_transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5Model.\n",
      "\n",
      "All the layers of TFT5Model were initialized from the model checkpoint at /Users/PRVATE/HUggingFace_Models/t5-small/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load HF model\n",
    "\n",
    "# Always do this\n",
    "\n",
    "\n",
    "model_hf_location = '/Users/PRVATE/HUggingFace_Models/t5-small/'\n",
    "model_hf = TFT5Model.from_pretrained(model_hf_location)\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"/Users/PRVATE/HUggingFace_Models/t5-small/\",\n",
       "  \"architectures\": [\n",
       "    \"T5WithLMHeadModel\"\n",
       "  ],\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 6,\n",
       "  \"num_heads\": 8,\n",
       "  \"num_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hf.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model_layer, model, config = T5Model(model_name='t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Deleteing huggingface model for saving memory\n",
      "INFO:absl:Done assigning ENCODER variables weights 51\n",
      "INFO:absl:Deleteing huggingface model for saving memory\n",
      "INFO:absl:Done assigning DECODER variables weights 81\n"
     ]
    }
   ],
   "source": [
    "convert_t5_hf_to_tf_transformers(model_hf, model, config['encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embeddings tf.Tensor(-125.860725, shape=(), dtype=float32)\n",
      "all_layer_token_embeddings tf.Tensor(-192280.42, shape=(), dtype=float32)\n",
      "token_logits tf.Tensor(-103934104.0, shape=(), dtype=float32)\n",
      "last_token_logits tf.Tensor(-19607434.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inputs_sample = {'encoder_input_ids': tf.constant([[8774,    6,   82, 1782,   19, 5295]]), \n",
    "                 'encoder_input_mask': tf.constant([[1, 1, 1, 1, 1, 1]]), \n",
    "                 'decoder_input_ids': tf.constant([[8774,    6,   82, 1782,   19, 5295]])}\n",
    "\n",
    "res = model(inputs_sample)\n",
    "for k, v in res.items():\n",
    "    print(k, tf.reduce_sum(v))\n",
    "    \n",
    "# Reference \n",
    "\n",
    "# token_embeddings tf.Tensor(-125.860725, shape=(), dtype=float32)\n",
    "# all_layer_token_embeddings tf.Tensor(-192280.42, shape=(), dtype=float32)\n",
    "# token_logits tf.Tensor(-103934104.0, shape=(), dtype=float32)\n",
    "# last_token_logits tf.Tensor(-19607434.0, shape=(), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Saved model at /Users/PRVATE/LegacyAI_models/t5-small/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "model.save_checkpoint(\"/Users/PRVATE/LegacyAI_models/t5-small/\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.5792198 2739 tf.Tensor(-12332620.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[   0 2739]], shape=(1, 2), dtype=int32)\n",
      "-----------------\n",
      "39.560272 4445 tf.Tensor(-14821873.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[   0 2739 4445]], shape=(1, 3), dtype=int32)\n",
      "-----------------\n",
      "-31.229576 436 tf.Tensor(-14894206.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[   0 2739 4445  436]], shape=(1, 4), dtype=int32)\n",
      "-----------------\n",
      "-67.342186 292 tf.Tensor(-16596788.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[   0 2739 4445  436  292]], shape=(1, 5), dtype=int32)\n",
      "-----------------\n",
      "-6.252556 58 tf.Tensor(-15607945.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[   0 2739 4445  436  292   58]], shape=(1, 6), dtype=int32)\n",
      "-----------------\n",
      "-118.80247 1 tf.Tensor(-18228060.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[   0 2739 4445  436  292   58    1]], shape=(1, 7), dtype=int32)\n",
      "-----------------\n",
      "-63.030956 1 tf.Tensor(-12004529.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[   0 2739 4445  436  292   58    1    1]], shape=(1, 8), dtype=int32)\n",
      "-----------------\n",
      "-16.752626 10 tf.Tensor(-9946732.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[   0 2739 4445  436  292   58    1    1   10]], shape=(1, 9), dtype=int32)\n",
      "-----------------\n",
      "-31.18003 3 tf.Tensor(-10146046.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[   0 2739 4445  436  292   58    1    1   10    3]], shape=(1, 10), dtype=int32)\n",
      "-----------------\n",
      "1.3379288 2 tf.Tensor(-11181468.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[   0 2739 4445  436  292   58    1    1   10    3    2]], shape=(1, 11), dtype=int32)\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Lets do a simple decode\n",
    "\n",
    "# Greedy decoding ( Train mode)\n",
    "\n",
    "# -3.5792198 2739 tf.Tensor(-12332620.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739]], shape=(1, 2), dtype=int32)\n",
    "# -----------------\n",
    "# 39.560272 4445 tf.Tensor(-14821873.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445]], shape=(1, 3), dtype=int32)\n",
    "# -----------------\n",
    "# -31.229576 436 tf.Tensor(-14894206.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436]], shape=(1, 4), dtype=int32)\n",
    "# -----------------\n",
    "# -67.342186 292 tf.Tensor(-16596788.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292]], shape=(1, 5), dtype=int32)\n",
    "# -----------------\n",
    "# -6.252556 58 tf.Tensor(-15607945.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58]], shape=(1, 6), dtype=int32)\n",
    "# -----------------\n",
    "# -118.80247 1 tf.Tensor(-18228060.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58    1]], shape=(1, 7), dtype=int32)\n",
    "# -----------------\n",
    "# -63.030956 1 tf.Tensor(-12004529.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58    1    1]], shape=(1, 8), dtype=int32)\n",
    "# -----------------\n",
    "# -16.752626 10 tf.Tensor(-9946732.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58    1    1   10]], shape=(1, 9), dtype=int32)\n",
    "# -----------------\n",
    "# -31.18003 3 tf.Tensor(-10146046.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58    1    1   10    3]], shape=(1, 10), dtype=int32)\n",
    "# -----------------\n",
    "# 1.3379288 2 tf.Tensor(-11181468.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58    1    1   10    3    2]], shape=(1, 11), dtype=int32)\n",
    "\n",
    "encoder_input_ids   = tf.constant([[13959,  1566,    12,  2968,    10,   571,   625,    33,    25,\n",
    "           58]])\n",
    "encoder_input_mask  = tf.constant([[1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1]])\n",
    "decoder_input_ids   = tf.constant([[0]])\n",
    "encoder_hidden_states = tf.zeros((1, 10, 512))\n",
    "\n",
    "encoder_decoder_inputs = {'encoder_input_ids': encoder_input_ids, \n",
    "                          'encoder_input_mask': encoder_input_mask, \n",
    "                          'decoder_input_ids': decoder_input_ids\n",
    "                         }\n",
    "best_res = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "\n",
    "    results = model(encoder_decoder_inputs)\n",
    "    best_prob, best_index = tf.nn.top_k(results['last_token_logits'][0], k=1)\n",
    "    # Concataning with previous\n",
    "    new_dec_ids = tf.concat([encoder_decoder_inputs['decoder_input_ids'], [best_index]], axis=1)\n",
    "    encoder_decoder_inputs['decoder_input_ids'] = new_dec_ids\n",
    "    print(best_prob[0].numpy() , best_index[0].numpy(), tf.reduce_sum(results['last_token_logits']))\n",
    "    best_res.append((best_prob[0].numpy(), best_index[0].numpy()))\n",
    "    print(new_dec_ids)\n",
    "    print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate English to German: How old are you?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoder_decoder_inputs['encoder_input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Wie alt sind Sie?</s>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([   0, 2739, 4445,  436,  292,   58,    1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 8, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 8, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 512), dtype=float32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 8, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 8, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model_layer , model, config = T5Model(model_name='t5-small',\n",
    "                                      is_training=False,\n",
    "                                      pipeline_mode='auto-regressive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.EncoderDecoder object at 0x14e38dbe0> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x14f057850>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.EncoderDecoder object at 0x14e38dbe0> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x14f057850>).\n",
      "INFO:absl:Succesful: Model checkpoints matched\n"
     ]
    }
   ],
   "source": [
    "model.load_checkpoint(\"/Users/PRVATE/LegacyAI_models/t5-small/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.5792198 2739\n",
      "tf.Tensor([[2739]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "39.560226 4445\n",
      "tf.Tensor([[4445]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "-31.229538 436\n",
      "tf.Tensor([[436]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "-67.3422 292\n",
      "tf.Tensor([[292]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "-6.25251 58\n",
      "tf.Tensor([[58]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "-118.80236 1\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "-63.030945 1\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "-16.752628 10\n",
      "tf.Tensor([[10]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "-31.180037 3\n",
      "tf.Tensor([[3]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "1.3379478 2\n",
      "tf.Tensor([[2]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Greedy decoding Using (AR pipeline caching)\n",
    "\n",
    "encoder_input_ids   = tf.constant([[13959,  1566,    12,  2968,    10,   571,   625,    33,    25,\n",
    "           58]])\n",
    "encoder_input_mask  = tf.constant([[1, 1, 1, 1, 1, 1, 1, 1 ,1 ,1]])\n",
    "decoder_input_ids   = tf.constant([[0]])\n",
    "encoder_hidden_states = tf.zeros((1, 10, config['encoder']['embedding_size']))\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "sequence_length = 1\n",
    "# (self.num_hidden_layers, batch_size, self.num_attention_heads, sequence_length, self.embedding_size//self.num_attention_heads)\n",
    "all_cache_key  =  tf.zeros((config['encoder']['num_hidden_layers'],\n",
    "                            batch_size, \n",
    "                            config['encoder']['num_attention_heads'], \n",
    "                            sequence_length, config['encoder']['embedding_size']//config['encoder']['num_attention_heads']))\n",
    "\n",
    "\n",
    "all_cache_value = tf.zeros_like(all_cache_key)\n",
    "\n",
    "encoder_decoder_inputs = {'encoder_input_ids': encoder_input_ids, \n",
    "                          'encoder_input_mask': encoder_input_mask, \n",
    "                          'decoder_input_ids': decoder_input_ids,\n",
    "                          'encoder_hidden_states': encoder_hidden_states,\n",
    "                          'decoder_all_cache_key': all_cache_key,\n",
    "                          'decoder_all_cache_value': all_cache_value\n",
    "                         }\n",
    "\n",
    "best_res = []\n",
    "for i in range(10):\n",
    "\n",
    "\n",
    "    results = model(encoder_decoder_inputs)\n",
    "    best_prob, best_index = tf.nn.top_k(results['last_token_logits'][0], k=1)\n",
    "    \n",
    "    # Concataning with previous\n",
    "    new_dec_ids = tf.expand_dims(best_index, axis=1)\n",
    "    encoder_decoder_inputs['decoder_input_ids'] = new_dec_ids\n",
    "    encoder_decoder_inputs['decoder_all_cache_key'] = results['decoder_all_cache_key']\n",
    "    encoder_decoder_inputs['decoder_all_cache_value'] = results['decoder_all_cache_value']\n",
    "    encoder_decoder_inputs['encoder_hidden_states'] = results['encoder_hidden_states']\n",
    "    print(best_prob[0].numpy() , best_index[0].numpy())\n",
    "    best_res.append((best_prob[0].numpy() , best_index[0].numpy()))\n",
    "    print(new_dec_ids)\n",
    "    print('-----------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(1, 128), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(1, 128), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(1, 128), dtype=int32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(1, 128), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(1, 128), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(1, 128), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Train mode (Keras Layer/Legacy Layer)\n",
    "\n",
    "enc_dec_model = EncoderDecoder(encoder=encoder_layer,\n",
    "                  decoder=decoder_layer,\n",
    "                  encoder_sequence_length=sequence_length,\n",
    "                  is_training=True, \n",
    "                  name='t5_small', \n",
    "                  use_dropout=False\n",
    "                  )\n",
    "\n",
    "enc_dec_model = enc_dec_model.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'decoder_input_ids:0' shape=(1, 128) dtype=int32>,\n",
       " <tf.Tensor 'input_ids:0' shape=(1, 128) dtype=int32>,\n",
       " <tf.Tensor 'input_mask:0' shape=(1, 128) dtype=int32>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec_model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp_pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp_pb/assets\n"
     ]
    }
   ],
   "source": [
    "enc_dec_model.save(\"tmp_pb\", save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'tmp_pb'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_dir) # path to the SavedModel directory\n",
    "# converter.experimental_new_converter = False\n",
    "converter.experimental_new_converter = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
     ]
    }
   ],
   "source": [
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r tmp_pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
