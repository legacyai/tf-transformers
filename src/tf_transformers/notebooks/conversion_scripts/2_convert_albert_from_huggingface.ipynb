{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/home/tf_transformers2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/Crypto/Random/Fortuna/FortunaGenerator.py:28: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if sys.version_info[0] is 2 and  sys.version_info[1] is 1:\n",
      "/usr/lib/python3/dist-packages/Crypto/Random/Fortuna/FortunaGenerator.py:28: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if sys.version_info[0] is 2 and  sys.version_info[1] is 1:\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAlbertModel\n",
    "from tf_transformers.models import AlbertEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "from tf_transformers.utils import convert_albert_hf_to_tf_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing TFAlbertModel.\n",
      "\n",
      "All the weights of TFAlbertModel were initialized from the model checkpoint at /mnt/home/PRE_MODELS/HuggingFace_models/albert-base-v2/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load HF model\n",
    "\n",
    "# Always do this\n",
    "\n",
    "\n",
    "model_hf_location = '/mnt/home/PRE_MODELS/HuggingFace_models/albert-base-v2/'\n",
    "model_hf = TFAlbertModel.from_pretrained(model_hf_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:input_type_ids ---> Tensor(\"input_type_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:input_ids ---> Tensor(\"input_ids_1:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:input_mask ---> Tensor(\"input_mask_1:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:input_type_ids ---> Tensor(\"input_type_ids_1:0\", shape=(None, None), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Load tf_transformers model\n",
    "# Most config we will be providing\n",
    "\n",
    "# Default configs for the model\n",
    "config_location = '/mnt/home/tf_transformers2/tf_transformers/model_directory/albert_base_v2/albert_config.json'\n",
    "config = json.load(open(config_location))\n",
    "\n",
    "# Always do this\n",
    "\n",
    "\n",
    "# tf_transformers Layer (an extension of Keras Layer)\n",
    "# This is not Keras model, but extension of keras Layer\n",
    "\n",
    "\n",
    "model_layer = AlbertEncoder(config=config,\n",
    "                      name='albert',\n",
    "                      mask_mode=config['mask_mode'],\n",
    "                      is_training=False, \n",
    "                      use_dropout=False,\n",
    "                      )\n",
    "# model_dir = None, because we have not initialized the model with proper variable values\n",
    "model_tf_transformers = model_layer.get_and_load_model(model_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Deleteing huggingface model for saving memory\n",
      "INFO:absl:Done assigning variables weights. Total 25\n"
     ]
    }
   ],
   "source": [
    "convert_albert_hf_to_tf_transformers(model_hf, model_tf_transformers, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_output --> tf.Tensor(12.337944, shape=(), dtype=float32) --> (2, 768)\n",
      "token_embeddings --> tf.Tensor(-193.53145, shape=(), dtype=float32) --> (2, 5, 768)\n"
     ]
    }
   ],
   "source": [
    "# Please have a look at tf_transformers/extra/*.py for reference values\n",
    "\n",
    "input_ids  = tf.constant([[1, 9, 10, 11, 23], \n",
    "                         [1, 22, 234, 432, 2349]])\n",
    "input_mask = tf.ones_like(input_ids)\n",
    "input_type_ids = tf.ones_like(input_ids)\n",
    "\n",
    "inputs = {'input_ids': input_ids, \n",
    "          'input_mask': input_mask, \n",
    "          'input_type_ids': input_type_ids}\n",
    "\n",
    "results_tf_transformers   = model_tf_transformers(inputs)\n",
    "for k, r in results_tf_transformers.items():\n",
    "    if isinstance(r, list):\n",
    "        continue\n",
    "    print(k, '-->', tf.reduce_sum(r), '-->', r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-193.53175, shape=(), dtype=float32) --> (2, 5, 768)\n",
      "tf.Tensor(12.337847, shape=(), dtype=float32) --> (2, 768)\n"
     ]
    }
   ],
   "source": [
    "# Huggingface Model\n",
    "input_ids  = tf.constant([[1, 9, 10, 11, 23], \n",
    "                         [1, 22, 234, 432, 2349]])\n",
    "input_mask = tf.ones_like(input_ids)\n",
    "input_type_ids = tf.ones_like(input_ids)\n",
    "\n",
    "results_hf = model_hf([input_ids, input_mask, input_type_ids])\n",
    "for k in results_hf:\n",
    "    print(tf.reduce_sum(k), '-->', k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
