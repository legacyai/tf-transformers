{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/home/TF_NEW/tf-transformers/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFMT5Model, T5Tokenizer\n",
    "from tf_transformers.models import mT5Model\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tf_transformers.utils import convert_mt5_hf_to_tf_transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at /Users/PRVATE/HUggingFace_Models/mt5-small/ were not used when initializing TFMT5Model: ['lm_head']\n",
      "- This IS expected if you are initializing TFMT5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFMT5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFMT5Model were initialized from the model checkpoint at /Users/PRVATE/HUggingFace_Models/mt5-small/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMT5Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load HF model\n",
    "\n",
    "# Always do this\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model_hf_location = '/Users/PRVATE/HUggingFace_Models/mt5-small/'\n",
    "model_hf = TFMT5Model.from_pretrained(model_hf_location)\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Initialized Variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer_with_weights-0.model_ouputs.all_layer_token_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer_with_weights-0.model_ouputs.all_layer_token_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer_with_weights-0.decoder.model_ouputs.all_layer_token_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer_with_weights-0.decoder.model_ouputs.all_layer_token_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer_with_weights-0.model_ouputs.all_layer_token_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer_with_weights-0.model_ouputs.all_layer_token_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer_with_weights-0.decoder.model_ouputs.all_layer_token_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model.layer_with_weights-0.decoder.model_ouputs.all_layer_token_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model_layer, model, config = mT5Model(model_name='mt5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Deleteing huggingface model for saving memory\n",
      "INFO:absl:Done assigning ENCODER variables weights 75\n",
      "INFO:absl:Deleteing huggingface model for saving memory\n",
      "INFO:absl:Done assigning DECODER variables weights 115\n"
     ]
    }
   ],
   "source": [
    "convert_mt5_hf_to_tf_transformers(model_hf, model, config['encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save checkpoint\n",
    "model.save_checkpoint(\"/Users/PRVATE/LegacyAI_models/mt5-small/\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embeddings tf.Tensor(-20.499813, shape=(), dtype=float32)\n",
      "all_layer_token_embeddings tf.Tensor(-222329.97, shape=(), dtype=float32)\n",
      "token_logits tf.Tensor(42779436.0, shape=(), dtype=float32)\n",
      "last_token_logits tf.Tensor(5198241.5, shape=(), dtype=float32)\n",
      "encoder_hidden_states tf.Tensor(52.110146, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inputs_sample = {'encoder_input_ids': tf.constant([[8774,    6,   82, 1782,   19, 5295]]), \n",
    "                 'encoder_input_mask': tf.constant([[1, 1, 1, 1, 1, 1]]), \n",
    "                 'decoder_input_ids': tf.constant([[8774,    6,   82, 1782,   19, 5295]])}\n",
    "\n",
    "res = model(inputs_sample)\n",
    "for k, v in res.items():\n",
    "    print(k, tf.reduce_sum(v))\n",
    "    \n",
    "# Reference \n",
    "\n",
    "# token_embeddings tf.Tensor(-125.860725, shape=(), dtype=float32)\n",
    "# all_layer_token_embeddings tf.Tensor(-192280.42, shape=(), dtype=float32)\n",
    "# token_logits tf.Tensor(-103934104.0, shape=(), dtype=float32)\n",
    "# last_token_logits tf.Tensor(-19607434.0, shape=(), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_hf(input_ids=inputs_sample['encoder_input_ids'], decoder_input_ids=inputs_sample['decoder_input_ids'])\n",
    "# for k, v in res.items():\n",
    "#     print(k, tf.reduce_sum(v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-20.501228>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(res.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3216.4043 217189 tf.Tensor(16623835.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[     0 217189]], shape=(1, 2), dtype=int32)\n",
      "-----------------\n",
      "5409.611 217189 tf.Tensor(32614544.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[     0 217189 217189]], shape=(1, 3), dtype=int32)\n",
      "-----------------\n",
      "2621.8142 217189 tf.Tensor(11411722.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[     0 217189 217189 217189]], shape=(1, 4), dtype=int32)\n",
      "-----------------\n",
      "1972.4235 147087 tf.Tensor(4441350.5, shape=(), dtype=float32)\n",
      "tf.Tensor([[     0 217189 217189 217189 147087]], shape=(1, 5), dtype=int32)\n",
      "-----------------\n",
      "2357.5967 14607 tf.Tensor(27313216.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[     0 217189 217189 217189 147087  14607]], shape=(1, 6), dtype=int32)\n",
      "-----------------\n",
      "2490.151 83261 tf.Tensor(25318396.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[     0 217189 217189 217189 147087  14607  83261]], shape=(1, 7), dtype=int32)\n",
      "-----------------\n",
      "2035.7072 219777 tf.Tensor(13057432.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[     0 217189 217189 217189 147087  14607  83261 219777]], shape=(1, 8), dtype=int32)\n",
      "-----------------\n",
      "2539.765 138182 tf.Tensor(4956161.5, shape=(), dtype=float32)\n",
      "tf.Tensor([[     0 217189 217189 217189 147087  14607  83261 219777 138182]], shape=(1, 9), dtype=int32)\n",
      "-----------------\n",
      "2815.1362 138182 tf.Tensor(11576028.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[     0 217189 217189 217189 147087  14607  83261 219777 138182 138182]], shape=(1, 10), dtype=int32)\n",
      "-----------------\n",
      "3328.351 207669 tf.Tensor(9023962.0, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[     0 217189 217189 217189 147087  14607  83261 219777 138182 138182\n",
      "  207669]], shape=(1, 11), dtype=int32)\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Lets do a simple decode\n",
    "\n",
    "# Greedy decoding ( Train mode)\n",
    "\n",
    "# -3.5792198 2739 tf.Tensor(-12332620.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739]], shape=(1, 2), dtype=int32)\n",
    "# -----------------\n",
    "# 39.560272 4445 tf.Tensor(-14821873.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445]], shape=(1, 3), dtype=int32)\n",
    "# -----------------\n",
    "# -31.229576 436 tf.Tensor(-14894206.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436]], shape=(1, 4), dtype=int32)\n",
    "# -----------------\n",
    "# -67.342186 292 tf.Tensor(-16596788.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292]], shape=(1, 5), dtype=int32)\n",
    "# -----------------\n",
    "# -6.252556 58 tf.Tensor(-15607945.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58]], shape=(1, 6), dtype=int32)\n",
    "# -----------------\n",
    "# -118.80247 1 tf.Tensor(-18228060.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58    1]], shape=(1, 7), dtype=int32)\n",
    "# -----------------\n",
    "# -63.030956 1 tf.Tensor(-12004529.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58    1    1]], shape=(1, 8), dtype=int32)\n",
    "# -----------------\n",
    "# -16.752626 10 tf.Tensor(-9946732.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58    1    1   10]], shape=(1, 9), dtype=int32)\n",
    "# -----------------\n",
    "# -31.18003 3 tf.Tensor(-10146046.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58    1    1   10    3]], shape=(1, 10), dtype=int32)\n",
    "# -----------------\n",
    "# 1.3379288 2 tf.Tensor(-11181468.0, shape=(), dtype=float32)\n",
    "# tf.Tensor([[   0 2739 4445  436  292   58    1    1   10    3    2]], shape=(1, 11), dtype=int32)\n",
    "\n",
    "encoder_input_ids   = tf.constant([[37194, 5413, 288, 20567, 267, 5100, 6801, 418, 521, 291, 1]])\n",
    "encoder_input_mask  = tf.ones_like(encoder_input_ids)\n",
    "decoder_input_ids   = tf.constant([[0]])\n",
    "encoder_hidden_states = tf.zeros((1, 11, 512))\n",
    "\n",
    "encoder_decoder_inputs = {'encoder_input_ids': encoder_input_ids, \n",
    "                          'encoder_input_mask': encoder_input_mask, \n",
    "                          'decoder_input_ids': decoder_input_ids\n",
    "                         }\n",
    "best_res = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "\n",
    "    results = model(encoder_decoder_inputs)\n",
    "    best_prob, best_index = tf.nn.top_k(results['last_token_logits'][0], k=1)\n",
    "    # Concataning with previous\n",
    "    new_dec_ids = tf.concat([encoder_decoder_inputs['decoder_input_ids'], [best_index]], axis=1)\n",
    "    encoder_decoder_inputs['decoder_input_ids'] = new_dec_ids\n",
    "    print(best_prob[0].numpy() , best_index[0].numpy(), tf.reduce_sum(results['last_token_logits']))\n",
    "    best_res.append((best_prob[0].numpy(), best_index[0].numpy()))\n",
    "    print(new_dec_ids)\n",
    "    print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We are overwriding `is_training` is False to `is_training` to True with `use_dropout` is False, no effects on your inference pipeline\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 6, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 6, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 512), dtype=float32)\n",
      "INFO:absl:Initialized Variables\n",
      "INFO:absl:Inputs -->\n",
      "INFO:absl:encoder_input_ids ---> Tensor(\"input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:encoder_input_mask ---> Tensor(\"input_mask:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_input_ids ---> Tensor(\"decoder_input_ids:0\", shape=(None, None), dtype=int32)\n",
      "INFO:absl:decoder_all_cache_key ---> Tensor(\"all_cache_key:0\", shape=(None, None, 6, None, 64), dtype=float32)\n",
      "INFO:absl:decoder_all_cache_value ---> Tensor(\"all_cache_value:0\", shape=(None, None, 6, None, 64), dtype=float32)\n",
      "INFO:absl:encoder_hidden_states ---> Tensor(\"encoder_hidden_states:0\", shape=(None, None, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model_layer , model, config = mT5Model(model_name='mt5-small',\n",
    "                                      is_training=False,\n",
    "                                      pipeline_mode='auto-regressive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.EncoderDecoder object at 0x169fdb4c0> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x15e9fa220>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tf_transformers.models.encoder_decoder.EncoderDecoder object at 0x169fdb4c0> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x15e9fa220>).\n",
      "INFO:absl:Succesful: Model checkpoints matched\n"
     ]
    }
   ],
   "source": [
    "model.load_checkpoint(\"/Users/PRVATE/LegacyAI_models/mt5-small/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.14633 217189\n",
      "tf.Tensor([[217189]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "239.07336 217189\n",
      "tf.Tensor([[217189]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "115.86856 217189\n",
      "tf.Tensor([[217189]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "87.16968 147087\n",
      "tf.Tensor([[147087]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "104.192024 14607\n",
      "tf.Tensor([[14607]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "110.05008 83261\n",
      "tf.Tensor([[83261]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "89.96649 219777\n",
      "tf.Tensor([[219777]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "112.242065 138182\n",
      "tf.Tensor([[138182]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "124.41264 138182\n",
      "tf.Tensor([[138182]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n",
      "147.09375 207669\n",
      "tf.Tensor([[207669]], shape=(1, 1), dtype=int32)\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# Greedy decoding Using (AR pipeline caching)\n",
    "\n",
    "encoder_input_ids   = tf.constant([[37194, 5413, 288, 20567, 267, 5100, 6801, 418, 521, 291, 1]])\n",
    "encoder_input_mask  = tf.ones_like(encoder_input_ids)\n",
    "decoder_input_ids   = tf.constant([[0]])\n",
    "encoder_hidden_states = tf.zeros((1, 11, config['encoder']['embedding_size']))\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "sequence_length = 1\n",
    "# (self.num_hidden_layers, batch_size, self.num_attention_heads, sequence_length, self.embedding_size//self.num_attention_heads)\n",
    "all_cache_key  =  tf.zeros((config['encoder']['num_hidden_layers'],\n",
    "                            batch_size, \n",
    "                            config['encoder']['num_attention_heads'], \n",
    "                            sequence_length, config['encoder']['embedding_size']//config['encoder']['num_attention_heads']))\n",
    "\n",
    "\n",
    "all_cache_value = tf.zeros_like(all_cache_key)\n",
    "\n",
    "encoder_decoder_inputs = {'encoder_input_ids': encoder_input_ids, \n",
    "                          'encoder_input_mask': encoder_input_mask, \n",
    "                          'decoder_input_ids': decoder_input_ids,\n",
    "                          'encoder_hidden_states': encoder_hidden_states,\n",
    "                          'decoder_all_cache_key': all_cache_key,\n",
    "                          'decoder_all_cache_value': all_cache_value\n",
    "                         }\n",
    "\n",
    "best_res = []\n",
    "for i in range(10):\n",
    "\n",
    "\n",
    "    results = model(encoder_decoder_inputs)\n",
    "    best_prob, best_index = tf.nn.top_k(results['last_token_logits'][0], k=1)\n",
    "    \n",
    "    # Concataning with previous\n",
    "    new_dec_ids = tf.expand_dims(best_index, axis=1)\n",
    "    encoder_decoder_inputs['decoder_input_ids'] = new_dec_ids\n",
    "    encoder_decoder_inputs['decoder_all_cache_key'] = results['decoder_all_cache_key']\n",
    "    encoder_decoder_inputs['decoder_all_cache_value'] = results['decoder_all_cache_value']\n",
    "    encoder_decoder_inputs['encoder_hidden_states'] = results['encoder_hidden_states']\n",
    "    print(best_prob[0].numpy() , best_index[0].numpy())\n",
    "    best_res.append((best_prob[0].numpy() , best_index[0].numpy()))\n",
    "    print(new_dec_ids)\n",
    "    print('-----------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
